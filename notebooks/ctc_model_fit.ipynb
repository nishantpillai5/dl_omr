{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 18:55:11.314793: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-17 18:55:11.314857: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D, Layer\n",
    "from keras.layers import Input, Dense, Activation, LeakyReLU, Permute, Bidirectional, CuDNNLSTM\n",
    "from keras.layers import Reshape, Lambda, BatchNormalization\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from primus import CTC_PriMuS\n",
    "import ctc_utils\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from primus import CTC_PriMuS\n",
    "import ctc_utils\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_model_params(img_height, vocabulary_size):\n",
    "    params = dict()\n",
    "    params['img_height'] = img_height\n",
    "    params['img_width'] = None\n",
    "    params['batch_size'] = 128\n",
    "    params['img_channels'] = 1\n",
    "    params['conv_blocks'] = 4\n",
    "    params['conv_filter_n'] = [32, 64, 128, 256]\n",
    "    params['conv_filter_size'] = [ [3,3], [3,3], [3,3], [3,3] ]\n",
    "    params['conv_pooling_size'] = [ [2,2], [2,2], [2,2], [2,2] ]\n",
    "    params['rnn_units'] = 128\n",
    "    params['rnn_layers'] = 2\n",
    "    params['vocabulary_size'] = vocabulary_size\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = K.ctc_batch_cost\n",
    "        # self.loss_fn = K.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "\n",
    "        #labels = Input(name='the_labels', shape=[max_seq_len], dtype='float32') # (None ,8)\n",
    "        #input_length = Input(name='input_length', shape=[1], dtype='int64')     # (None, 1)\n",
    "        #label_length = Input(name='label_length', shape=[1], dtype='int64')     # (None, 1)\n",
    "\n",
    "        #loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length]) #(None, 1)\n",
    "\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ctc_crnn(params,width_rem = 128):\n",
    "    input_shape = (params['img_height'],params['img_width'], params['img_channels'])\n",
    "\n",
    "    inputs = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "\n",
    "    labels = Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
    "\n",
    "    width_reduction = 1\n",
    "    height_reduction = 1\n",
    "\n",
    "    #conv2d layer\n",
    "    for i in range(params['conv_blocks']):\n",
    "            inner = Conv2D(params['conv_filter_n'][i], params['conv_filter_size'][i], padding='same', name='conv'+ str(i+1), kernel_initializer='he_normal')(inputs if i == 0 else inner)\n",
    "            inner = BatchNormalization()(inner)\n",
    "            inner = LeakyReLU(0.2)(inner)\n",
    "            inner = MaxPooling2D(pool_size=params['conv_pooling_size'][i], strides = params['conv_pooling_size'][i], name='max' + str(i+1))(inner)\n",
    "\n",
    "            width_reduction = width_reduction * params['conv_pooling_size'][i][1]\n",
    "            height_reduction = height_reduction * params['conv_pooling_size'][i][0]\n",
    "\n",
    "            \n",
    "    features = K.permute_dimensions(inner, (2,0,3,1))\n",
    "    feature_dim = params['conv_filter_n'][-1] * (params['img_height'] / height_reduction)\n",
    "    feature_width = width_rem / width_reduction\n",
    "    features = tf.reshape(features, tf.stack([tf.cast(feature_width,'int32'), 16, tf.cast(feature_dim,'int32')]))\n",
    "    \n",
    "    # RNN block\n",
    "    lstm_1 = CuDNNLSTM(params['rnn_units'], return_sequences=True, kernel_initializer='he_normal', name='lstm1')(features)  # (None, 32, 512)\n",
    "    lstm_1b = CuDNNLSTM(params['rnn_units'], return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm1_b')(features)\n",
    "    reversed_lstm_1b = Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_1b)\n",
    "\n",
    "    lstm1_merged = add([lstm_1, reversed_lstm_1b])  # (None, 32, 512)\n",
    "    lstm1_merged = BatchNormalization()(lstm1_merged)\n",
    "    \n",
    "    lstm_2 = CuDNNLSTM(params['rnn_units'], return_sequences=True, kernel_initializer='he_normal', name='lstm2')(lstm1_merged)\n",
    "    lstm_2b = CuDNNLSTM(params['rnn_units'], return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm2_b')(lstm1_merged)\n",
    "    reversed_lstm_2b= Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_2b)\n",
    "\n",
    "    lstm2_merged = concatenate([lstm_2, reversed_lstm_2b])  # (None, 32, 1024)\n",
    "    lstm2_merged = BatchNormalization()(lstm2_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    num_classes = params['vocabulary_size'] + 1\n",
    "    inner = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(lstm2_merged) #(None, 32, 63)\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, y_pred)\n",
    "\n",
    "\n",
    "    return Model(inputs=[inputs, labels], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 9000 and validating with 1000\n"
     ]
    }
   ],
   "source": [
    "corpus_dirpath = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/primusCalvoRizoAppliedSciences2018/\"\n",
    "corpus_filepath = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/train.txt\"\n",
    "dictionary_path = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/vocabulary_semantic.txt\"\n",
    "primus = CTC_PriMuS(corpus_dirpath,corpus_filepath,dictionary_path, True, val_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " the_input (InputLayer)         [(None, 128, None,   0           []                               \n",
      "                                1)]                                                               \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 128, None, 3  320         ['the_input[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128, None, 3  128        ['conv1[0][0]']                  \n",
      " alization)                     2)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 128, None, 3  0           ['batch_normalization[0][0]']    \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " max1 (MaxPooling2D)            (None, 64, None, 32  0           ['leaky_re_lu[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 64, None, 64  18496       ['max1[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 64, None, 64  256        ['conv2[0][0]']                  \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 64, None, 64  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max2 (MaxPooling2D)            (None, 32, None, 64  0           ['leaky_re_lu_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3 (Conv2D)                 (None, 32, None, 12  73856       ['max2[0][0]']                   \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, None, 12  512        ['conv3[0][0]']                  \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 32, None, 12  0           ['batch_normalization_2[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max3 (MaxPooling2D)            (None, 16, None, 12  0           ['leaky_re_lu_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv4 (Conv2D)                 (None, 16, None, 25  295168      ['max3[0][0]']                   \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, None, 25  1024       ['conv4[0][0]']                  \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 16, None, 25  0           ['batch_normalization_3[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " max4 (MaxPooling2D)            (None, 8, None, 256  0           ['leaky_re_lu_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TFOpLa  (None, None, 256, 8  0          ['max4[0][0]']                   \n",
      " mbda)                          )                                                                 \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (8, 16, 2048)        0           ['tf.compat.v1.transpose[0][0]'] \n",
      "                                                                                                  \n",
      " lstm1_b (CuDNNLSTM)            (8, 16, 128)         1115136     ['tf.reshape[0][0]']             \n",
      "                                                                                                  \n",
      " lstm1 (CuDNNLSTM)              (8, 16, 128)         1115136     ['tf.reshape[0][0]']             \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (8, 16, 128)         0           ['lstm1_b[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (8, 16, 128)         0           ['lstm1[0][0]',                  \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (8, 16, 128)        512         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " lstm2_b (CuDNNLSTM)            (8, 16, 128)         132096      ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " lstm2 (CuDNNLSTM)              (8, 16, 128)         132096      ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (8, 16, 128)         0           ['lstm2_b[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (8, 16, 256)         0           ['lstm2[0][0]',                  \n",
      "                                                                  'lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (8, 16, 256)        1024        ['concatenate[0][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (8, 16, 1782)        457974      ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " softmax (Activation)           (8, 16, 1782)        0           ['dense2[0][0]']                 \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)            (8, 16, 1782)        0           ['label[0][0]',                  \n",
      "                                                                  'softmax[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,343,734\n",
      "Trainable params: 3,342,006\n",
      "Non-trainable params: 1,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Parameterization\n",
    "img_height = 128\n",
    "params = default_model_params(img_height,primus.vocabulary_size)\n",
    "max_epochs = 100\n",
    "dropout = 0.5\n",
    "\n",
    "# Model\n",
    "model = ctc_crnn(params)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "image_paths = []\n",
    "image_texts = []\n",
    "\n",
    "class PriMuS_Data:\n",
    "    def __init__(self, corpus_dirpath, corpus_filepath, dictionary_path):\n",
    "        self.corpus_dirpath = corpus_dirpath\n",
    "\n",
    "        # Corpus\n",
    "        corpus_file = open(corpus_filepath,'r')\n",
    "        self.corpus_list = corpus_file.read().splitlines()\n",
    "        corpus_file.close()\n",
    "\n",
    "        self.current_idx = 0\n",
    "\n",
    "        # Dictionary\n",
    "        self.word2int = {}\n",
    "        self.int2word = {}\n",
    "            \n",
    "        dict_file = open(dictionary_path,'r')\n",
    "        dict_list = dict_file.read().splitlines()\n",
    "        for word in dict_list:\n",
    "            if not word in self.word2int:\n",
    "                word_idx = len(self.word2int)\n",
    "                self.word2int[word] = word_idx\n",
    "                self.int2word[word_idx] = word\n",
    "\n",
    "        dict_file.close()\n",
    "\n",
    "        self.vocabulary_size = len(self.word2int)\n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.corpus_list\n",
    "    \n",
    "    def trim_ds(self):\n",
    "        val_split = 0.9\n",
    "        folder_path = self.corpus_dirpath\n",
    "        list_of_files = self.corpus_list #10,000 filenames\n",
    "\n",
    "        image_paths = [self.corpus_dirpath+f\"{x}/{x}.png\" for x in self.corpus_list] # list of image paths\n",
    "        text_paths = [self.corpus_dirpath+f\"{x}/{x}.semantic\" for x in self.corpus_list]\n",
    "\n",
    "        image_texts = [] # list of strings\n",
    "\n",
    "        for path in text_paths:\n",
    "            with open(path, \"r\") as file:\n",
    "                image_texts.append(file.readline())\n",
    "\n",
    "\n",
    "        train_image_paths = image_paths[ : int(len(image_paths) * val_split)]\n",
    "        train_image_texts = image_texts[ : int(len(image_texts) * val_split)]\n",
    "\n",
    "        val_image_paths = image_paths[int(len(image_paths) * val_split) : ]\n",
    "        val_image_texts = image_texts[int(len(image_texts) * val_split) : ]\n",
    "\n",
    "        return {\"train\":{\"images\":train_image_paths, \"text\": train_image_texts}, \"val\":{\"images\":val_image_paths, \"text\": val_image_texts}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obj = PriMuS_Data(corpus_dirpath, corpus_filepath, dictionary_path)\n",
    "lst = data_obj.trim_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images to desired dimensions with unknown width\n",
    "def resize_no_width(image, height):\n",
    "    width = int(float(height * image.shape[1]) / image.shape[0])\n",
    "    sample_img = cv2.resize(image, (width, height))\n",
    "    return sample_img\n",
    "\n",
    "\n",
    "# Pre-process a single image sample(resize/normalize/max_width resize)\n",
    "def process_single_sample(img_path, label, nowidth = True, max_width = 0):\n",
    "    params = default_model_params(img_height,primus.vocabulary_size)\n",
    "    # 1. Read image\n",
    "    img = tf.io.read_file(img_path)\n",
    "    # 2. Decode and convert to grayscale\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    # 3. Convert to float32 in [0, 1] range\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # 4. Resize to the desired size\n",
    "    if nowidth:\n",
    "        img = resize_no_width(img, params['img_height'])\n",
    "    else:\n",
    "        img = tf.image.resize(img,[params['img_height'], max_width])\n",
    "    # TODO: Get height from params, calculate width from max of all images\n",
    "    return {\"image\": img, \"label\": label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = process_single_sample(lst[\"train\"][\"images\"][0],lst[\"train\"][\"text\"][0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <tf.Tensor: shape=(32, 128, 1), dtype=float32, numpy=\n",
       " array([[[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       " \n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       " \n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        ],\n",
       "         [0.21960786],\n",
       "         [0.21960786],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       " \n",
       "        [[1.        ],\n",
       "         [0.21960786],\n",
       "         [0.21960786],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       " \n",
       "        [[1.        ],\n",
       "         [0.21960786],\n",
       "         [0.26057082],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]]], dtype=float32)>,\n",
       " 'label': 'clef-C1\\tkeySignature-EbM\\ttimeSignature-3/4\\tmultirest-10\\tbarline\\tnote-Bb4_quarter\\tnote-Eb4_eighth\\tnote-Eb5_eighth\\tnote-Eb5_eighth\\tnote-C5_eighth\\tbarline\\tnote-Ab4_eighth\\tnote-Ab4_eighth\\trest-quarter\\trest-quarter\\tbarline\\tnote-F5_quarter\\tnote-Eb5_eighth.\\tnote-C5_sixteenth\\tnote-Bb4_eighth.\\tnote-Ab4_sixteenth\\tbarline\\tnote-Ab4_eighth\\tnote-G4_eighth\\trest-quarter\\t'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((lst['train']['images'], lst['train']['text']))\n",
    "\n",
    "train_dataset = train_dataset.map(process_single_sample)\n",
    "image_widths = [img.shape[1] for img in train_dataset[0]]\n",
    "max_image_width = max(image_widths)\n",
    "train_dataset = train_dataset.map(process_single_sample(nowidth = False, max_width = max_image_width))\n",
    "    \n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((lst['val']['images'], lst['val']['text']))\n",
    "validation_dataset = (\n",
    "    validation_dataset.batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/rajesh-bhat/spark-ai-summit-2020-text-extraction/blob/master/CRNN_CTC_wandb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "model.compile(optimizer = optimizer)\n",
    "\n",
    "history = model.fit(train_dataset, \n",
    "                    epochs = max_epochs,\n",
    "                    validation_data=validation_dataset,\n",
    "                    verbose = 1,\n",
    "                    # callbacks = callbacks_list,\n",
    "                    shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4353fa2223bcff818cc061505deebebd3ad0598b3b9db22646ace266afa50fc"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
