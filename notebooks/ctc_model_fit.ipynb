{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D, Layer\n",
    "from keras.layers import Input, Dense, Activation, LeakyReLU, Permute, Bidirectional, CuDNNLSTM\n",
    "from keras.layers import Reshape, Lambda, BatchNormalization\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from primus import CTC_PriMuS\n",
    "import ctc_utils\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from primus import CTC_PriMuS\n",
    "import ctc_utils\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_model_params(img_height, vocabulary_size):\n",
    "    params = dict()\n",
    "    params['img_height'] = img_height\n",
    "    params['img_width'] = None\n",
    "    params['batch_size'] = 128\n",
    "    params['img_channels'] = 1\n",
    "    params['conv_blocks'] = 2\n",
    "    params['conv_filter_n'] = [32, 64]\n",
    "    params['conv_filter_size'] = [ [3,3], [3,3] ]\n",
    "    params['conv_pooling_size'] = [ [2,2], [2,2] ]\n",
    "    params['rnn_units'] = 32\n",
    "    params['rnn_layers'] = 1\n",
    "    params['vocabulary_size'] = vocabulary_size\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = K.ctc_batch_cost\n",
    "        # self.loss_fn = K.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\") # 16\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        print(\"Y_pred shape:  \",y_pred.shape)\n",
    "        print(\"Y_true shape:  \",y_true.shape)\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ctc_crnn(params,width_rem = 128):\n",
    "    input_shape = (params['img_height'],width_rem, params['img_channels'])\n",
    "\n",
    "    inputs = Input(name='image', shape=input_shape, dtype='float32')\n",
    "\n",
    "    labels = Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
    "\n",
    "    width_reduction = 1\n",
    "    height_reduction = 1\n",
    "\n",
    "    #conv2d layer\n",
    "    for i in range(params['conv_blocks']):\n",
    "            inner = Conv2D(params['conv_filter_n'][i], params['conv_filter_size'][i], padding='same', name='conv'+ str(i+1), kernel_initializer='he_normal')(inputs if i == 0 else inner)\n",
    "            inner = BatchNormalization()(inner)\n",
    "            inner = LeakyReLU(0.2)(inner)\n",
    "            inner = MaxPooling2D(pool_size=params['conv_pooling_size'][i], strides = params['conv_pooling_size'][i], name='max' + str(i+1))(inner)\n",
    "\n",
    "            width_reduction = width_reduction * params['conv_pooling_size'][i][1]\n",
    "            height_reduction = height_reduction * params['conv_pooling_size'][i][0]\n",
    "           \n",
    "    \n",
    "#     print(width_reduction)\n",
    "#     features = K.permute_dimensions(inner, (2,0,3,1))\n",
    "#     feature_dim = params['conv_filter_n'][-1] * (params['img_height'] / height_reduction)\n",
    "#     feature_width = width_rem / width_reduction\n",
    "#     print(\"Feature width:\",feature_width)\n",
    "#     features = tf.reshape(features, tf.stack([tf.cast(feature_width,'int32'), 16, tf.cast(feature_dim,'int32')]))\n",
    "    \n",
    "#     # RNN block\n",
    "#     lstm_1 = CuDNNLSTM(params['rnn_units'], return_sequences=True, kernel_initializer='he_normal', name='lstm1')(features)  # (None, 32, 512)\n",
    "#     lstm_1b = CuDNNLSTM(params['rnn_units'], return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm1_b')(features)\n",
    "#     reversed_lstm_1b = Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_1b)\n",
    "\n",
    "#     lstm1_merged = add([lstm_1, reversed_lstm_1b])  # (None, 32, 512)\n",
    "#     lstm1_merged = BatchNormalization()(lstm1_merged)\n",
    "    \n",
    "#     lstm_2 = CuDNNLSTM(params['rnn_units'], return_sequences=True, kernel_initializer='he_normal', name='lstm2')(lstm1_merged)\n",
    "#     lstm_2b = CuDNNLSTM(params['rnn_units'], return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm2_b')(lstm1_merged)\n",
    "#     reversed_lstm_2b= Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_2b)\n",
    "\n",
    "#     lstm2_merged = concatenate([lstm_2, reversed_lstm_2b])  # (None, 32, 1024)\n",
    "#     lstm2_merged = BatchNormalization()(lstm2_merged)\n",
    "\n",
    "#     # transforms RNN output to character activations:\n",
    "#     num_classes = params['vocabulary_size'] + 1\n",
    "#     inner = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(lstm2_merged) #(None, 32, 63)\n",
    "#     y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "    squeezed = Reshape((-1, inner.shape[-3] * inner.shape[-1]))(inner)\n",
    "    # squeezed = Lambda(lambda x: K.squeeze(x, 1))(inner)\n",
    "\n",
    "    # bidirectional LSTM layers with units=128\n",
    "    blstm_1 = Bidirectional(CuDNNLSTM(128, return_sequences=True))(squeezed)\n",
    "    blstm_2 = Bidirectional(CuDNNLSTM(128, return_sequences=True))(blstm_1)\n",
    "    num_classes = params['vocabulary_size'] + 1\n",
    "    softmax_output = Dense(num_classes + 1, activation = 'softmax', name=\"dense\")(blstm_2)\n",
    "\n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, softmax_output)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "  \n",
    "#     inner = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(lstm2_merged) #(None, 32, 63)\n",
    "#     y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "\n",
    "    return Model(inputs=[inputs, labels], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 176 and validating with 43\n"
     ]
    }
   ],
   "source": [
    "corpus_dirpath = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/primusCalvoRizoAppliedSciences2018/\"\n",
    "corpus_filepath = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/train.txt\"\n",
    "dictionary_path = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/vocabulary_semantic.txt\"\n",
    "primus = CTC_PriMuS(corpus_dirpath,corpus_filepath,dictionary_path, True, val_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "image_paths = []\n",
    "image_texts = []\n",
    "\n",
    "class PriMuS_Data:\n",
    "    def __init__(self, corpus_dirpath, corpus_filepath, dictionary_path):\n",
    "        self.corpus_dirpath = corpus_dirpath\n",
    "\n",
    "        # Corpus\n",
    "        corpus_file = open(corpus_filepath,'r')\n",
    "        self.corpus_list = corpus_file.read().splitlines()\n",
    "        corpus_file.close()\n",
    "\n",
    "        self.current_idx = 0\n",
    "\n",
    "        # Dictionary\n",
    "        self.word2int = {}\n",
    "        self.int2word = {}\n",
    "            \n",
    "        dict_file = open(dictionary_path,'r')\n",
    "        dict_list = dict_file.read().splitlines()\n",
    "        for word in dict_list:\n",
    "            if not word in self.word2int:\n",
    "                word_idx = len(self.word2int)\n",
    "                self.word2int[word] = word_idx\n",
    "                self.int2word[word_idx] = word\n",
    "\n",
    "        dict_file.close()\n",
    "\n",
    "        self.vocabulary_size = len(self.word2int)\n",
    "    \n",
    "    def get_vocabulary_size(self):\n",
    "        return self.vocabulary_size\n",
    "        \n",
    "    def get_data(self):\n",
    "        return self.corpus_list\n",
    "\n",
    "    def encode_seqs(self, seqs):\n",
    "        encoded = []\n",
    "        for seq in seqs:\n",
    "            new_seq=[]\n",
    "            for sym in seq:\n",
    "                new_seq.append(self.word2int[sym])\n",
    "            encoded.append(new_seq)\n",
    "        return encoded\n",
    "\n",
    "    def trim_ds(self):\n",
    "        val_split = 0.9\n",
    "        folder_path = self.corpus_dirpath\n",
    "        list_of_files = self.corpus_list #10,000 filenames\n",
    "\n",
    "        image_paths = [self.corpus_dirpath+f\"{x}/{x}.png\" for x in self.corpus_list] # list of image paths\n",
    "        text_paths = [self.corpus_dirpath+f\"{x}/{x}.semantic\" for x in self.corpus_list]\n",
    "\n",
    "        image_texts = [] # list of strings\n",
    "\n",
    "        for path in text_paths:\n",
    "            with open(path, \"r\") as file:\n",
    "                image_texts.append(file.readline().split())\n",
    "\n",
    "        image_texts = self.encode_seqs(image_texts)\n",
    "\n",
    "        max_label_len = max([len(seq) for seq in image_texts])\n",
    "        padded_image_texts = pad_sequences(image_texts, maxlen=max_label_len, padding='post', value= self.vocabulary_size + 1)\n",
    "\n",
    "        # TODO: do line 17 from the link : https://github.com/rajesh-bhat/spark-ai-summit-2020-text-extraction/blob/master/CRNN_CTC_wandb.ipynb\n",
    "\n",
    "        # TODO: Use self.word2int to encode each element of the lists in image_texts\n",
    "        # Input image_texts = [  ['clef','C-note'] , [.......], ....]\n",
    "        # Final image_texts = [  [5,3] , [.......], ....]\n",
    "        # if 'clef' == 5, 'C-note' == 3 in word2int dictionary\n",
    "        # Also add padding using the function below so length of each element is consistent\n",
    "\n",
    "        # from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "        # padded_image_texts = list(map(encode_to_labels, image_texts))\n",
    "        # padded_image_texts[0]\n",
    "\n",
    "\n",
    "        train_image_paths = image_paths[ : int(len(image_paths) * val_split)]\n",
    "        train_image_texts = padded_image_texts[ : int(len(padded_image_texts) * val_split)]\n",
    "\n",
    "        val_image_paths = image_paths[int(len(image_paths) * val_split) : ]\n",
    "        val_image_texts = padded_image_texts[int(len(padded_image_texts) * val_split) : ]\n",
    "\n",
    "        return {\"train\":{\"images\":train_image_paths, \"text\": train_image_texts}, \"val\":{\"images\":val_image_paths, \"text\": val_image_texts}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obj = PriMuS_Data(corpus_dirpath, corpus_filepath, dictionary_path)\n",
    "lst = data_obj.trim_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do line 17 from the link : https://github.com/rajesh-bhat/spark-ai-summit-2020-text-extraction/blob/master/CRNN_CTC_wandb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781\n"
     ]
    }
   ],
   "source": [
    "print(data_obj.vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images to desired dimensions with unknown width\n",
    "def resize_no_width(image, height):\n",
    "    width = int(float(height * image.shape[1]) / image.shape[0])\n",
    "    sample_img = cv2.resize(image, (width, height))\n",
    "    return sample_img\n",
    "\n",
    "\n",
    "# Pre-process a single image sample(resize/normalize/max_width resize)\n",
    "def process_single_sample(img_path, label,max_width = 30):\n",
    "    params = default_model_params(img_height,primus.vocabulary_size)\n",
    "    # 1. Read image\n",
    "    img = tf.io.read_file(img_path)\n",
    "    # 2. Decode and convert to grayscale\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    # 3. Convert to float32 in [0, 1] range\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # 4. Resize to the desired size\n",
    "    img = tf.image.resize(img,[params['img_height'], max_width])\n",
    "    # TODO: Get height from params, calculate width from max of all images\n",
    "    return {\"image\": img, \"label\": label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n",
      "Y_pred shape:   (None, 500, 1783)\n",
      "Y_true shape:   (None, None)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image (InputLayer)             [(None, 64, 2002, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 64, 2002, 32  320         ['image[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 64, 2002, 32  128        ['conv1[0][0]']                  \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 64, 2002, 32  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max1 (MaxPooling2D)            (None, 32, 1001, 32  0           ['leaky_re_lu_12[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 32, 1001, 64  18496       ['max1[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 1001, 64  256        ['conv2[0][0]']                  \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 32, 1001, 64  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max2 (MaxPooling2D)            (None, 16, 500, 64)  0           ['leaky_re_lu_13[0][0]']         \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 500, 1024)    0           ['max2[0][0]']                   \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 500, 256)    1181696     ['reshape_1[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 500, 256)    395264      ['bidirectional_2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 500, 1783)    458231      ['bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)            (None, 500, 1783)    0           ['label[0][0]',                  \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,054,391\n",
      "Trainable params: 2,054,199\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "\n",
    "image_widths = [cv2.imread(img).shape[1] for img in lst[\"train\"][\"images\"]]\n",
    "max_image_width = max(image_widths)\n",
    "print(max_image_width)\n",
    "# Parameterization\n",
    "img_height = 64\n",
    "params = default_model_params(img_height,primus.vocabulary_size)\n",
    "max_epochs = 100\n",
    "dropout = 0.5\n",
    "# Model\n",
    "model = ctc_crnn(params, width_rem= max_image_width)\n",
    "model.summary()\n",
    "\n",
    "# Pre-process a single image sample(resize/normalize/max_width resize)\n",
    "def process_single_sample(img_path, label):\n",
    "    params = default_model_params(img_height,primus.vocabulary_size)\n",
    "    # 1. Read image\n",
    "    img = tf.io.read_file(img_path)\n",
    "    # 2. Decode and convert to grayscale\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    # 3. Convert to float32 in [0, 1] range\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # 4. Resize to the desired size\n",
    "    img = tf.image.resize(img,[params['img_height'], max_image_width])\n",
    "    # TODO: Get height from params, calculate width from max of all images\n",
    "    return {\"image\": img, \"label\": label}\n",
    "# train_dataset = train_dataset.map(process_single_sample(max_width = max_image_width))\n",
    "\n",
    "# processed_images = [process_single_sample(img,label,max_image_width) for img,label in zip(lst[\"train\"][\"images\"], lst[\"train\"][\"text\"])]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((lst['train']['images'], lst['train']['text']))\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.map(\n",
    "        process_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((lst['val']['images'], lst['val']['text']))\n",
    "validation_dataset = (\n",
    "    validation_dataset.map(\n",
    "        process_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.Series(image_widths)\n",
    "plt.hist(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/rajesh-bhat/spark-ai-summit-2020-text-extraction/blob/master/CRNN_CTC_wandb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Y_pred shape:   (None, 500, 1783)\n",
      "Y_true shape:   (None, 33)\n",
      "Y_pred shape:   (None, 500, 1783)\n",
      "Y_true shape:   (None, 33)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/batch_normalization_13/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\steli\\AppData\\Local\\Temp\\ipykernel_684\\825552303.py\", line 19, in <cell line: 19>\n      history = model.fit(train_dataset,\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 767, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 623, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 105, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 589, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model_1/batch_normalization_13/FusedBatchNormV3'\nDetected at node 'model_1/batch_normalization_13/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\steli\\AppData\\Local\\Temp\\ipykernel_684\\825552303.py\", line 19, in <cell line: 19>\n      history = model.fit(train_dataset,\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 767, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 623, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 105, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 589, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model_1/batch_normalization_13/FusedBatchNormV3'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[32,64,32,1001] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/batch_normalization_13/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[model_1/ctc_loss/Log/_76]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[32,64,32,1001] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/batch_normalization_13/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_7544]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\steli\\DeepLearning\\Project\\dl_omr\\notebooks\\ctc_model_fit.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit.ipynb#ch0000014?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer \u001b[39m=\u001b[39m optimizer)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit.ipynb#ch0000014?line=5'>6</a>\u001b[0m \u001b[39m# checkpoint = ModelCheckpoint(filepath=file_path, \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit.ipynb#ch0000014?line=6'>7</a>\u001b[0m \u001b[39m#                                 monitor='val_loss', \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit.ipynb#ch0000014?line=7'>8</a>\u001b[0m \u001b[39m#                                 verbose=1, \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit.ipynb#ch0000014?line=15'>16</a>\u001b[0m \u001b[39m#                       PlotPredictions(frequency=1),\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit.ipynb#ch0000014?line=16'>17</a>\u001b[0m \u001b[39m#                       EarlyStopping(patience=3, verbose=1)]\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit.ipynb#ch0000014?line=18'>19</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_dataset, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit.ipynb#ch0000014?line=19'>20</a>\u001b[0m                     epochs \u001b[39m=\u001b[39;49m max_epochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit.ipynb#ch0000014?line=20'>21</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mvalidation_dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit.ipynb#ch0000014?line=21'>22</a>\u001b[0m                     verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit.ipynb#ch0000014?line=22'>23</a>\u001b[0m                     \u001b[39m# callbacks = callbacks_list,\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit.ipynb#ch0000014?line=23'>24</a>\u001b[0m                     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/batch_normalization_13/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\steli\\AppData\\Local\\Temp\\ipykernel_684\\825552303.py\", line 19, in <cell line: 19>\n      history = model.fit(train_dataset,\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 767, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 623, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 105, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 589, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model_1/batch_normalization_13/FusedBatchNormV3'\nDetected at node 'model_1/batch_normalization_13/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\steli\\AppData\\Local\\Temp\\ipykernel_684\\825552303.py\", line 19, in <cell line: 19>\n      history = model.fit(train_dataset,\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 767, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 623, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 105, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 589, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model_1/batch_normalization_13/FusedBatchNormV3'\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[32,64,32,1001] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/batch_normalization_13/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[model_1/ctc_loss/Log/_76]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[32,64,32,1001] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/batch_normalization_13/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_7544]"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "model.compile(optimizer = optimizer)\n",
    "\n",
    "# checkpoint = ModelCheckpoint(filepath=file_path, \n",
    "#                                 monitor='val_loss', \n",
    "#                                 verbose=1, \n",
    "#                                 save_best_only=True, \n",
    "#                                 mode='min')\n",
    "\n",
    "#     callbacks_list = [checkpoint, \n",
    "#                       WandbCallback(monitor=\"val_loss\", \n",
    "#                                     mode=\"min\", \n",
    "#                                     log_weights=True),\n",
    "#                       PlotPredictions(frequency=1),\n",
    "#                       EarlyStopping(patience=3, verbose=1)]\n",
    "\n",
    "history = model.fit(train_dataset, \n",
    "                    epochs = max_epochs,\n",
    "                    validation_data=validation_dataset,\n",
    "                    verbose = 1,\n",
    "                    # callbacks = callbacks_list,\n",
    "                    shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9bbe03f6c4bbdf56f443191d16980388af1b731aba7be9951b0256cee325895"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
