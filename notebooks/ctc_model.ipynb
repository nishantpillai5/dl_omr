{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation, LeakyReLU, Permute\n",
    "from keras.layers import Reshape, Lambda, BatchNormalization, Bidirectional\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "def default_model_params(img_height, vocabulary_size):\n",
    "    params = dict()\n",
    "    params['img_height'] = img_height\n",
    "    params['img_width'] = None\n",
    "    params['batch_size'] = 16\n",
    "    params['img_channels'] = 1\n",
    "    params['conv_blocks'] = 4\n",
    "    params['conv_filter_n'] = [32, 64, 128, 256]\n",
    "    params['conv_filter_size'] = [[3,3], [3,3], [3,3], [3,3]]\n",
    "    params['conv_pooling_size'] = [[2,2], [2,2], [2,2], [2,2]]\n",
    "    params['rnn_units'] = 512\n",
    "    params['rnn_layers'] = 2\n",
    "    params['vocabulary_size'] = vocabulary_size\n",
    "    return params\n",
    "\n",
    "\n",
    "# # Loss and train functions, network architecture\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def ctc_crnn(params, training = True, width_rem=128):\n",
    "    input_shape = (params['img_height'],params['img_width'], params['img_channels'])\n",
    "\n",
    "    inputs = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    width_reduction = 1\n",
    "    height_reduction = 1\n",
    "\n",
    "    #Conv2d layers\n",
    "    for i in range(params['conv_blocks']):\n",
    "        inner = Conv2D(params['conv_filter_n'][i], params['conv_filter_size'][i], padding='same', name='conv'+ str(i+1), kernel_initializer='he_normal')( inputs if i == 0 else inner)\n",
    "        inner = BatchNormalization()(inner)\n",
    "        inner = LeakyReLU(0.2)(inner)\n",
    "        inner = MaxPooling2D(pool_size=params['conv_pooling_size'][i], strides = params['conv_pooling_size'][i], name='max' + str(i+1))(inner)\n",
    "\n",
    "        width_reduction = width_reduction * params['conv_pooling_size'][i][1]\n",
    "        height_reduction = height_reduction * params['conv_pooling_size'][i][0]\n",
    "\n",
    "\n",
    "    features = K.permute_dimensions(inner, (2,0,3,1))\n",
    "    feature_dim = params['conv_filter_n'][-1] * (params['img_height'] / height_reduction)\n",
    "    # feature_width = input_shape[1] / width_reduction\n",
    "    feature_width = width_rem / width_reduction\n",
    "    # features = tf.reshape(features, tf.stack([tf.cast(feature_width,'int32'), inputs.shape[0], tf.cast(feature_dim,'int32')]))\n",
    "    features = tf.reshape(features, tf.stack([tf.cast(feature_width,'int32'), 16, tf.cast(feature_dim,'int32')]))\n",
    "\n",
    "    inner = Reshape(target_shape=((8, params['conv_filter_n'][-1])), name='reshape')(inner)\n",
    "\n",
    "    #Recurrent layers\n",
    "    lstm_1 = LSTM(512, return_sequences=True, kernel_initializer='he_normal', name='lstm1')(inner)  # (None, 32, 512)\n",
    "    lstm_1b = LSTM(512, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm1_b')(inner)\n",
    "    reversed_lstm_1b = Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_1b)\n",
    "\n",
    "    lstm1_merged = add([lstm_1, reversed_lstm_1b])  # (None, 32, 512)\n",
    "    lstm1_merged = BatchNormalization()(lstm1_merged)\n",
    "    \n",
    "    lstm_2 = LSTM(512, return_sequences=True, kernel_initializer='he_normal', name='lstm2')(lstm1_merged)\n",
    "    lstm_2b = LSTM(512, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm2_b')(lstm1_merged)\n",
    "    reversed_lstm_2b= Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_2b)\n",
    "\n",
    "    lstm2_merged = concatenate([lstm_2, reversed_lstm_2b])  # (None, 32, 1024)\n",
    "    lstm2_merged = BatchNormalization()(lstm2_merged)\n",
    "    inner = Dense(params['vocabulary_size'] + 1, kernel_initializer='he_normal',name='dense2')(lstm2_merged)\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[max_text_len], dtype='float32') # (None ,8)\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')     # (None, 1)\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')     # (None, 1)\n",
    "\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length]) #(None, 1)\n",
    "\n",
    "    if training:\n",
    "        return Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
    "    else:\n",
    "        return Model(inputs=[inputs], outputs=y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " the_input (InputLayer)         [(None, 128, None,   0           []                               \n",
      "                                1)]                                                               \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 128, None, 3  320         ['the_input[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 128, None, 3  128        ['conv1[0][0]']                  \n",
      " ormalization)                  2)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_44 (LeakyReLU)     (None, 128, None, 3  0           ['batch_normalization_50[0][0]'] \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " max1 (MaxPooling2D)            (None, 64, None, 32  0           ['leaky_re_lu_44[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 64, None, 64  18496       ['max1[0][0]']                   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 64, None, 64  256        ['conv2[0][0]']                  \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_45 (LeakyReLU)     (None, 64, None, 64  0           ['batch_normalization_51[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max2 (MaxPooling2D)            (None, 32, None, 64  0           ['leaky_re_lu_45[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3 (Conv2D)                 (None, 32, None, 12  73856       ['max2[0][0]']                   \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 32, None, 12  512        ['conv3[0][0]']                  \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_46 (LeakyReLU)     (None, 32, None, 12  0           ['batch_normalization_52[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max3 (MaxPooling2D)            (None, 16, None, 12  0           ['leaky_re_lu_46[0][0]']         \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv4 (Conv2D)                 (None, 16, None, 25  295168      ['max3[0][0]']                   \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 16, None, 25  1024       ['conv4[0][0]']                  \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_47 (LeakyReLU)     (None, 16, None, 25  0           ['batch_normalization_53[0][0]'] \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " max4 (MaxPooling2D)            (None, 8, None, 256  0           ['leaky_re_lu_47[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 8, 256)       0           ['max4[0][0]']                   \n",
      "                                                                                                  \n",
      " lstm1_b (LSTM)                 (None, 8, 512)       1574912     ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " lstm1 (LSTM)                   (None, 8, 512)       1574912     ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              (None, 8, 512)       0           ['lstm1_b[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 8, 512)       0           ['lstm1[0][0]',                  \n",
      "                                                                  'lambda_6[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 8, 512)      2048        ['add_3[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " lstm2_b (LSTM)                 (None, 8, 512)       2099200     ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " lstm2 (LSTM)                   (None, 8, 512)       2099200     ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              (None, 8, 512)       0           ['lstm2_b[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 8, 1024)      0           ['lstm2[0][0]',                  \n",
      "                                                                  'lambda_7[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 8, 1024)     4096        ['concatenate_3[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 8, 2)         2050        ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, 8, 2)         0           ['dense2[0][0]']                 \n",
      "                                                                                                  \n",
      " the_labels (InputLayer)        [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " input_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " label_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " ctc (Lambda)                   (None, 1)            0           ['softmax[0][0]',                \n",
      "                                                                  'the_labels[0][0]',             \n",
      "                                                                  'input_length[0][0]',           \n",
      "                                                                  'label_length[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,746,178\n",
      "Trainable params: 7,742,146\n",
      "Non-trainable params: 4,032\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "temp = default_model_params(128,1)\n",
    "temp = ctc_crnn(temp)\n",
    "temp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(temp, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9bbe03f6c4bbdf56f443191d16980388af1b731aba7be9951b0256cee325895"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
