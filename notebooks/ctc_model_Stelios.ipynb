{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation, LeakyReLU, Permute, Bidirectional, CuDNNLSTM\n",
    "from keras.layers import Reshape, Lambda, BatchNormalization\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from primus import CTC_PriMuS\n",
    "import ctc_utils\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from primus import CTC_PriMuS\n",
    "import ctc_utils\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)\n",
    "\n",
    "def default_model_params(img_height, vocabulary_size):\n",
    "    params = dict()\n",
    "    params['img_height'] = img_height\n",
    "    params['img_width'] = None\n",
    "    params['batch_size'] = 128\n",
    "    params['img_channels'] = 1\n",
    "    params['conv_blocks'] = 4\n",
    "    params['conv_filter_n'] = [32, 64, 128, 256]\n",
    "    params['conv_filter_size'] = [ [3,3], [3,3], [3,3], [3,3] ]\n",
    "    params['conv_pooling_size'] = [ [2,2], [2,2], [2,2], [2,2] ]\n",
    "    params['rnn_units'] = 128\n",
    "    params['rnn_layers'] = 2\n",
    "    params['vocabulary_size'] = vocabulary_size\n",
    "    return params\n",
    "\n",
    "# def ctc_loss(y_true, y_pred, input_length, label_length, real_y_true_ts):\n",
    "#     return tf.keras.backend.ctc_batch_cost(real_y_true_ts, y_pred, input_length, label_length)\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # FIXME: Why?\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def ctc_crnn(params, max_seq_len, width_rem = 128, training = True):\n",
    "    input_shape = (params['img_height'],params['img_width'], params['img_channels'])\n",
    "\n",
    "    inputs = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    width_reduction = 1\n",
    "    height_reduction = 1\n",
    "\n",
    "    #conv2d layer\n",
    "    for i in range(params['conv_blocks']):\n",
    "            inner = Conv2D(params['conv_filter_n'][i], params['conv_filter_size'][i], padding='same', name='conv'+ str(i+1), kernel_initializer='he_normal')(inputs if i == 0 else inner)\n",
    "            inner = BatchNormalization()(inner)\n",
    "            inner = LeakyReLU(0.2)(inner)\n",
    "            inner = MaxPooling2D(pool_size=params['conv_pooling_size'][i], strides = params['conv_pooling_size'][i], name='max' + str(i+1))(inner)\n",
    "\n",
    "            width_reduction = width_reduction * params['conv_pooling_size'][i][1]\n",
    "            height_reduction = height_reduction * params['conv_pooling_size'][i][0]\n",
    "\n",
    "            \n",
    "    features = K.permute_dimensions(inner, (2,0,3,1))\n",
    "    feature_dim = params['conv_filter_n'][-1] * (params['img_height'] / height_reduction)\n",
    "    # feature_width = input_shape[1] / width_reduction\n",
    "    feature_width = width_rem / width_reduction\n",
    "    # features = tf.reshape(features, tf.stack([tf.cast(feature_width,'int32'), inputs.shape[0], tf.cast(feature_dim,'int32')]))\n",
    "    features = tf.reshape(features, tf.stack([tf.cast(feature_width,'int32'), 16, tf.cast(feature_dim,'int32')]))\n",
    "    \n",
    "    # RNN block\n",
    "    lstm_1 = CuDNNLSTM(params['rnn_units'], return_sequences=True, kernel_initializer='he_normal', name='lstm1')(features)  # (None, 32, 512)\n",
    "    lstm_1b = CuDNNLSTM(params['rnn_units'], return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm1_b')(features)\n",
    "    reversed_lstm_1b = Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_1b)\n",
    "\n",
    "    lstm1_merged = add([lstm_1, reversed_lstm_1b])  # (None, 32, 512)\n",
    "    lstm1_merged = BatchNormalization()(lstm1_merged)\n",
    "    \n",
    "    lstm_2 = CuDNNLSTM(params['rnn_units'], return_sequences=True, kernel_initializer='he_normal', name='lstm2')(lstm1_merged)\n",
    "    lstm_2b = CuDNNLSTM(params['rnn_units'], return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm2_b')(lstm1_merged)\n",
    "    reversed_lstm_2b= Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_2b)\n",
    "\n",
    "    lstm2_merged = concatenate([lstm_2, reversed_lstm_2b])  # (None, 32, 1024)\n",
    "    lstm2_merged = BatchNormalization()(lstm2_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    num_classes = params['vocabulary_size'] + 1\n",
    "    inner = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(lstm2_merged) #(None, 32, 63)\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "    # FIXME: Change based on data\n",
    "    labels = Input(name='the_labels', shape=[max_seq_len], dtype='float32') # (None ,8)\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')     # (None, 1)\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')     # (None, 1)\n",
    "\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length]) #(None, 1)\n",
    "\n",
    "    if training:\n",
    "        return Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
    "    else:\n",
    "        return Model(inputs=[inputs], outputs=y_pred)\n",
    "\n",
    "    # rnn_hidden_units = params['rnn_units']\n",
    "    # rnn_hidden_layers = params['rnn_layers']\n",
    "    # for i in range(rnn_hidden_layers):\n",
    "    #     inner = Bidirectional(LSTM(rnn_hidden_units,activation='softmax'))(features) # features if i == 0 else inner\n",
    "  \n",
    "    # inner = Dense(params['vocabulary_size'] + 1)(inner)\n",
    "    # y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "    # return Model(inputs=[inputs], outputs= lstm2_merged), loss_out\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 9000 and validating with 1000\n"
     ]
    }
   ],
   "source": [
    "corpus_dirpath = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/primusCalvoRizoAppliedSciences2018/\"\n",
    "corpus_filepath = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/train.txt\"\n",
    "vocabulary = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/vocabulary_semantic.txt\"\n",
    "primus = CTC_PriMuS(corpus_dirpath,corpus_filepath,vocabulary, True, val_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameterization\n",
    "img_height = 128\n",
    "params = default_model_params(img_height,primus.vocabulary_size)\n",
    "max_epochs = 100\n",
    "dropout = 0.5\n",
    "\n",
    "# Model\n",
    "model = ctc_crnn(params,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss= {'ctc': lambda y_true, y_pred: y_pred})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steli\\AppData\\Local\\Temp\\ipykernel_13080\\4294282738.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=primus.nextBatch(params),\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'dict'> containing {\"<class 'str'>\"} keys and {'(<class \\'list\\'> containing values of types {\\'(<class \\\\\\'list\\\\\\'> containing values of types {\"<class \\\\\\'int\\\\\\'>\"})\\'})', \"<class 'numpy.ndarray'>\"} values), <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\steli\\DeepLearning\\Project\\dl_omr\\notebooks\\ctc_model_Stelios.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_Stelios.ipynb#ch0000004?line=0'>1</a>\u001b[0m val_data, val_len \u001b[39m=\u001b[39m primus\u001b[39m.\u001b[39mgetValidation(params)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_Stelios.ipynb#ch0000004?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit_generator(generator\u001b[39m=\u001b[39;49mprimus\u001b[39m.\u001b[39;49mnextBatch(params),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_Stelios.ipynb#ch0000004?line=3'>4</a>\u001b[0m                     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(\u001b[39mlen\u001b[39;49m(primus\u001b[39m.\u001b[39;49mtraining_list) \u001b[39m/\u001b[39;49m params[\u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m]),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_Stelios.ipynb#ch0000004?line=4'>5</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49mmax_epochs,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_Stelios.ipynb#ch0000004?line=5'>6</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m val_data, \u001b[39m# FIXME: unsure\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_Stelios.ipynb#ch0000004?line=6'>7</a>\u001b[0m                     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(val_len \u001b[39m/\u001b[39;49m params[\u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:2209\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2197'>2198</a>\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2198'>2199</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2199'>2200</a>\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2200'>2201</a>\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2201'>2202</a>\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2202'>2203</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2203'>2204</a>\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2204'>2205</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2205'>2206</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2206'>2207</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2207'>2208</a>\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m-> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2208'>2209</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2209'>2210</a>\u001b[0m     generator,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2210'>2211</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2211'>2212</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2212'>2213</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2213'>2214</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2214'>2215</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2215'>2216</a>\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2216'>2217</a>\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2217'>2218</a>\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2218'>2219</a>\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2219'>2220</a>\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2220'>2221</a>\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2221'>2222</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=2222'>2223</a>\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:984\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/data_adapter.py?line=980'>981</a>\u001b[0m adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/data_adapter.py?line=981'>982</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/data_adapter.py?line=982'>983</a>\u001b[0m   \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/data_adapter.py?line=983'>984</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/data_adapter.py?line=984'>985</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/data_adapter.py?line=985'>986</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/data_adapter.py?line=986'>987</a>\u001b[0m           _type_name(x), _type_name(y)))\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/data_adapter.py?line=987'>988</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(adapter_cls) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/data_adapter.py?line=988'>989</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/data_adapter.py?line=989'>990</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mData adapters should be mutually exclusive for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/data_adapter.py?line=990'>991</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mhandling inputs. Found multiple adapters \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/data_adapter.py?line=991'>992</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/data_adapter.py?line=992'>993</a>\u001b[0m           adapter_cls, _type_name(x), _type_name(y)))\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'dict'> containing {\"<class 'str'>\"} keys and {'(<class \\'list\\'> containing values of types {\\'(<class \\\\\\'list\\\\\\'> containing values of types {\"<class \\\\\\'int\\\\\\'>\"})\\'})', \"<class 'numpy.ndarray'>\"} values), <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "\n",
    "val_data, val_len = primus.getValidation(params)\n",
    "\n",
    "model.fit_generator(generator=primus.nextBatch(params),\n",
    "                    steps_per_epoch=int(len(primus.training_list) / params['batch_size']),\n",
    "                    epochs=max_epochs,\n",
    "                    validation_data= val_data, # FIXME: unsure\n",
    "                    validation_steps=int(val_len / params['batch_size']))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9bbe03f6c4bbdf56f443191d16980388af1b731aba7be9951b0256cee325895"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
