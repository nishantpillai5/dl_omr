{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End Optical Music Recognition with CRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Layer\n",
    "# from tensorflow.keras.layers import Input, Dense, Activation, LeakyReLU, Permute, Bidirectional\n",
    "# from tensorflow.keras.layers import Reshape, Lambda, BatchNormalization, LSTM\n",
    "# from tensorflow.python.keras.layers.merge import add, concatenate\n",
    "# from tensorflow.python.keras.layers.recurrent import LSTM\n",
    "# from tensorflow.keras.layers import CuDNNLSTM\n",
    "from primus import CTC_PriMuS\n",
    "import ctc_utils\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_model_params(img_height, vocabulary_size):\n",
    "    params = dict()\n",
    "    params['img_height'] = img_height\n",
    "    params['img_width'] = None\n",
    "    params['batch_size'] = 16\n",
    "    params['img_channels'] = 1\n",
    "    params['conv_blocks'] = 2\n",
    "    params['conv_filter_n'] = [32, 64]\n",
    "    params['conv_filter_size'] = [ [3,3], [3,3] ]\n",
    "    params['conv_pooling_size'] = [ [2,2], [2,2] ]\n",
    "    params['rnn_units'] = 32\n",
    "    params['rnn_layers'] = 1\n",
    "    params['vocabulary_size'] = vocabulary_size\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = K.ctc_batch_cost\n",
    "        # self.loss_fn = K.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\") # 16\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        # print(\"Y_pred shape:  \",y_pred.shape)\n",
    "        # print(\"Y_true shape:  \",y_true.shape)\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "def buildModel(params, input_width, rnn_layers = 2, rnn_units = 128):\n",
    "    input_shape = (params['img_height'],params['img_width'], params['img_channels'])\n",
    "\n",
    "    inputs = layers.Input(type_spec=tf.TensorSpec(shape=[None, params['img_height'], input_width, 1], dtype=tf.float32), name = \"image\" )\n",
    "    # inputs = layers.Input(name='image', shape=input_shape, dtype='float32')\n",
    "\n",
    "    labels = layers.Input(type_spec=tf.TensorSpec(shape=[None, None], dtype=tf.float32), name = \"label\" )\n",
    "    # x = layers.Reshape((params['img_height'], input_width, 1), name=\"expand_dim\")(inputs)\n",
    "    x = layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size= [params['conv_filter_n'][0], params['conv_filter_n'][0]],\n",
    "        strides=[2, 2],\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"conv_1\",\n",
    "    )(inputs)\n",
    "    x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n",
    "    x = layers.ReLU(name=\"conv_1_relu\")(x)\n",
    "    x = layers.MaxPool2D(pool_size=params['conv_pooling_size'][0], strides = params['conv_pooling_size'][0], name='max1')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=[params['conv_filter_n'][1], params['conv_filter_n'][1]],\n",
    "        strides=[1, 2],\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"conv_2\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n",
    "    x = layers.ReLU(name=\"conv_2_relu\")(x)\n",
    "    x = layers.MaxPool2D(pool_size=params['conv_pooling_size'][1], strides = params['conv_pooling_size'][1], name='max2')(x)\n",
    "    print(x.shape)\n",
    "    x = layers.Reshape((-1, x.shape[-3] * x.shape[-1]))(x)\n",
    "\n",
    "    for i in range(1, rnn_layers + 1):\n",
    "        recurrent = layers.GRU(\n",
    "            units=rnn_units,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            use_bias=True,\n",
    "            return_sequences=True,\n",
    "            reset_after=True,\n",
    "            name=f\"gru_{i}\",\n",
    "        )\n",
    "        x = layers.Bidirectional(\n",
    "            recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\"\n",
    "        )(x)\n",
    "        if i < rnn_layers:\n",
    "            x = layers.Dropout(rate=0.35)(x)\n",
    "\n",
    "    num_classes = params['vocabulary_size'] + 1\n",
    "    y_pred = layers.Dense(num_classes, kernel_initializer='he_normal',name='dense2', activation='softmax')(x) #(None, 32, 63)        \n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, y_pred)\n",
    "    model = Model([inputs,labels], output, name=\"OMR\")\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "    model.compile(optimizer = optimizer)\n",
    "    # model.compile(optimizer=opt, loss=CTCLoss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 128\n",
    "corpus_dirpath = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/primusCalvoRizoAppliedSciences2018/\"\n",
    "corpus_filepath = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/train.txt\"\n",
    "dictionary_path = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/vocabulary_semantic.txt\"\n",
    "test_set_path = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/test.txt\"\n",
    "\n",
    "# primus = CTC_PriMuS(corpus_dirpath,corpus_filepath,dictionary_path, True, val_split = 0.2)\n",
    "\n",
    "# corpus_dirpath = \"/content/primusCalvoRizoAppliedSciences2018/\"\n",
    "# corpus_filepath = \"/content/train.txt\"\n",
    "# dictionary_path = \"/content/vocabulary_semantic.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete N lines from the train/test txt files for training purposes\n",
    "# with open(r\"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/train.txt\", 'r+') as fp:\n",
    "#     lines = fp.readlines()\n",
    "#     t = int(len(lines))\n",
    "#     print(t)\n",
    "#     # print(len(lines))\n",
    "#     fp.seek(0)\n",
    "#     fp.truncate()\n",
    "#     fp.writelines(lines[:-200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "image_paths = []\n",
    "image_texts = []\n",
    "\n",
    "class PriMuS_Data:\n",
    "    def __init__(self, corpus_dirpath, corpus_filepath, dictionary_path):\n",
    "        self.corpus_dirpath = corpus_dirpath\n",
    "\n",
    "        # Corpus\n",
    "        corpus_file = open(corpus_filepath,'r')\n",
    "        self.corpus_list = corpus_file.read().splitlines()\n",
    "        corpus_file.close()\n",
    "\n",
    "        self.current_idx = 0\n",
    "\n",
    "        # Dictionary\n",
    "        self.word2int = {}\n",
    "        self.int2word = {}\n",
    "            \n",
    "        dict_file = open(dictionary_path,'r')\n",
    "        dict_list = dict_file.read().splitlines()\n",
    "        for word in dict_list:\n",
    "            if not word in self.word2int:\n",
    "                word_idx = len(self.word2int)\n",
    "                self.word2int[word] = word_idx\n",
    "                self.int2word[word_idx] = word\n",
    "\n",
    "        dict_file.close()\n",
    "\n",
    "        self.vocabulary_size = len(self.word2int)\n",
    "    \n",
    "    def get_vocabulary_size(self):\n",
    "        return self.vocabulary_size\n",
    "        \n",
    "    def get_data(self):\n",
    "        return self.corpus_list\n",
    "\n",
    "    def encode_seqs(self, seqs):\n",
    "        encoded = []\n",
    "        for seq in seqs:\n",
    "            new_seq=[]\n",
    "            for sym in seq:\n",
    "                new_seq.append(self.word2int[sym])\n",
    "            encoded.append(new_seq)\n",
    "        return encoded\n",
    "\n",
    "    def decode_seqs(self, seqs): # [1,2,3,4,..] -> \"clef\\tC-note\"\n",
    "        decoded = []\n",
    "        for seq in seqs:\n",
    "            new_seq=\"\"\n",
    "            for sym in seq:\n",
    "                try:\n",
    "                    new_seq+= self.int2word[sym] + \"\\t\"\n",
    "                except KeyError:\n",
    "                    continue\n",
    "            new_seq = new_seq[:-1]\n",
    "            decoded.append(new_seq)\n",
    "        return decoded\n",
    "\n",
    "    def get_test(self):\n",
    "        obj = self.trim_ds(val_split=1) \n",
    "        return {\"images\": obj['train']['images'], \"text\":obj['train']['text']}\n",
    "\n",
    "    def trim_ds(self, val_split = 0.9):\n",
    "        folder_path = self.corpus_dirpath\n",
    "        list_of_files = self.corpus_list #10,000 filenames\n",
    "\n",
    "        image_paths = [self.corpus_dirpath+f\"{x}/{x}.png\" for x in self.corpus_list] # list of image paths\n",
    "        text_paths = [self.corpus_dirpath+f\"{x}/{x}.semantic\" for x in self.corpus_list]\n",
    "\n",
    "        image_texts = [] # list of strings\n",
    "\n",
    "        for path in text_paths:\n",
    "            with open(path, \"r\") as file:\n",
    "                image_texts.append(file.readline().split())\n",
    "\n",
    "        image_texts = self.encode_seqs(image_texts)\n",
    "\n",
    "        max_label_len = max([len(seq) for seq in image_texts])\n",
    "        print(max_label_len)\n",
    "        padded_image_texts = pad_sequences(image_texts, maxlen=max_label_len, padding='post', value= self.vocabulary_size + 1)\n",
    "\n",
    "        # TODO: do line 17 from the link : https://github.com/rajesh-bhat/spark-ai-summit-2020-text-extraction/blob/master/CRNN_CTC_wandb.ipynb\n",
    "\n",
    "        # TODO: Use self.word2int to encode each element of the lists in image_texts\n",
    "        # Input image_texts = [  ['clef','C-note'] , [.......], ....]\n",
    "        # Final image_texts = [  [5,3] , [.......], ....]\n",
    "        # if 'clef' == 5, 'C-note' == 3 in word2int dictionary\n",
    "        # Also add padding using the function below so length of each element is consistent\n",
    "\n",
    "        # from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "        # padded_image_texts = list(map(encode_to_labels, image_texts))\n",
    "        # padded_image_texts[0]\n",
    "\n",
    "\n",
    "        train_image_paths = image_paths[ : int(len(image_paths) * val_split)]\n",
    "        train_image_texts = padded_image_texts[ : int(len(padded_image_texts) * val_split)]\n",
    "\n",
    "        val_image_paths = image_paths[int(len(image_paths) * val_split) : ]\n",
    "        val_image_texts = padded_image_texts[int(len(padded_image_texts) * val_split) : ]\n",
    "\n",
    "        return {\"train\":{\"images\":train_image_paths, \"text\": train_image_texts}, \"val\":{\"images\":val_image_paths, \"text\": val_image_texts}}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "data_obj = PriMuS_Data(corpus_dirpath, corpus_filepath, dictionary_path)\n",
    "lst = data_obj.trim_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "data_obj_test = PriMuS_Data(corpus_dirpath, test_set_path, dictionary_path)\n",
    "lst_test = data_obj_test.get_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images to desired dimensions with unknown width\n",
    "def resize_no_width(image, height):\n",
    "    width = int(float(height * image.shape[1]) / image.shape[0])\n",
    "    sample_img = cv2.resize(image, (width, height))\n",
    "    return sample_img\n",
    "\n",
    "\n",
    "# Pre-process a single image sample(resize/normalize/max_width resize)\n",
    "def process_single_sample(img_path, label,max_width = 30):\n",
    "    params = default_model_params(img_height,primus.vocabulary_size)\n",
    "    # 1. Read image\n",
    "    img = tf.io.read_file(img_path)\n",
    "    # 2. Decode and convert to grayscale\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    # 3. Convert to float32 in [0, 1] range\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # 4. Resize to the desired size\n",
    "    img = tf.image.resize(img,[params['img_height'], max_width])\n",
    "    # TODO: Get height from params, calculate width from max of all images\n",
    "    return {\"image\": img, \"label\": label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003\n",
      "(None, 16, 125, 64)\n",
      "Model: \"OMR\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image (InputLayer)             [(None, 128, 2003,   0           []                               \n",
      "                                1)]                                                               \n",
      "                                                                                                  \n",
      " conv_1 (Conv2D)                (None, 64, 1002, 32  32768       ['image[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_1_bn (BatchNormalization)  (None, 64, 1002, 32  128        ['conv_1[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_1_relu (ReLU)             (None, 64, 1002, 32  0           ['conv_1_bn[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max1 (MaxPooling2D)            (None, 32, 501, 32)  0           ['conv_1_relu[0][0]']            \n",
      "                                                                                                  \n",
      " conv_2 (Conv2D)                (None, 32, 251, 64)  8388608     ['max1[0][0]']                   \n",
      "                                                                                                  \n",
      " conv_2_bn (BatchNormalization)  (None, 32, 251, 64)  256        ['conv_2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_2_relu (ReLU)             (None, 32, 251, 64)  0           ['conv_2_bn[0][0]']              \n",
      "                                                                                                  \n",
      " max2 (MaxPooling2D)            (None, 16, 125, 64)  0           ['conv_2_relu[0][0]']            \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 125, 1024)    0           ['max2[0][0]']                   \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 125, 256)    886272      ['reshape[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 125, 256)     0           ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 125, 256)    296448      ['dropout[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 125, 1782)    457974      ['bidirectional_2[0][0]']        \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)            (None, 125, 1782)    0           ['label[0][0]',                  \n",
      "                                                                  'dense2[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,062,454\n",
      "Trainable params: 10,062,262\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "\n",
    "image_widths = [cv2.imread(img).shape[1] for img in lst[\"train\"][\"images\"]]\n",
    "image_widths_2 = [cv2.imread(img).shape[1] for img in lst[\"val\"][\"images\"]]\n",
    "image_widths_3 = [cv2.imread(img).shape[1] for img in lst[\"train\"][\"images\"]]\n",
    "\n",
    "max_image_width = max(image_widths + image_widths_2 + image_widths_3)\n",
    "\n",
    "print(max_image_width)\n",
    "# Parameterization\n",
    "img_height = 128\n",
    "params = default_model_params(img_height,data_obj.vocabulary_size)\n",
    "max_epochs = 100\n",
    "dropout = 0.5\n",
    "# Model\n",
    "model = buildModel(params,input_width = max_image_width)\n",
    "model.summary()\n",
    "\n",
    "# Pre-process a single image sample(resize/normalize/max_width resize)\n",
    "def process_single_sample(img_path, label):\n",
    "    params = default_model_params(img_height,data_obj.vocabulary_size)\n",
    "    # 1. Read image\n",
    "    img = tf.io.read_file(img_path)\n",
    "    # 2. Decode and convert to grayscale\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    # 3. Convert to float32 in [0, 1] range\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # 4. Resize to the desired size\n",
    "    img = tf.image.resize(img,[params['img_height'], max_image_width])\n",
    "    # TODO: Get height from params, calculate width from max of all images\n",
    "    return {\"image\": img, \"label\": label}\n",
    "# train_dataset = train_dataset.map(process_single_sample(max_width = max_image_width))\n",
    "\n",
    "# processed_images = [process_single_sample(img,label,max_image_width) for img,label in zip(lst[\"train\"][\"images\"], lst[\"train\"][\"text\"])]\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((lst['train']['images'], lst['train']['text']))\n",
    "\n",
    "# train_dataset = (\n",
    "#     train_dataset.map(\n",
    "#         process_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "#     )\n",
    "#     .batch(batch_size)\n",
    "#     .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "# )\n",
    "\n",
    "# validation_dataset = tf.data.Dataset.from_tensor_slices((lst['val']['images'], lst['val']['text']))\n",
    "# validation_dataset = (\n",
    "#     validation_dataset.map(\n",
    "#         process_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "#     )\n",
    "#     .batch(batch_size)\n",
    "#     .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "# )\n",
    "def tfdata_generator_train(batch_size= batch_size):\n",
    "  '''Construct a data generator using `tf.Dataset`. '''\n",
    "  train_dataset = tf.data.Dataset.from_tensor_slices((lst['train']['images'], lst['train']['text']))\n",
    "  train_dataset = train_dataset.map(process_single_sample)\n",
    "  train_dataset = train_dataset.batch(batch_size)\n",
    "  # train_dataset = train_dataset.repeat()\n",
    "  train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "  return train_dataset\n",
    "\n",
    "def tfdata_generator_val(batch_size= batch_size):\n",
    "  '''Construct a data generator using `tf.Dataset`. '''\n",
    "  val_dataset = tf.data.Dataset.from_tensor_slices((lst['val']['images'], lst['val']['text']))\n",
    "  val_dataset = val_dataset.map(process_single_sample)\n",
    "  val_dataset = val_dataset.batch(batch_size)\n",
    "  # val_dataset = val_dataset.repeat()\n",
    "  val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "  return val_dataset\n",
    "\n",
    "def tfdata_generator_test(batch_size= batch_size):\n",
    "  '''Construct a data generator using `tf.Dataset`. '''\n",
    "  test_dataset = tf.data.Dataset.from_tensor_slices((lst_test['images'], lst_test['text']))\n",
    "  test_dataset = test_dataset.map(process_single_sample)\n",
    "  test_dataset = test_dataset.batch(batch_size)\n",
    "  # train_dataset = train_dataset.repeat()\n",
    "  test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "  return test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tfdata_generator_train()\n",
    "validation_dataset = tfdata_generator_val()\n",
    "test_dataset = tfdata_generator_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='../models/model.{epoch:02d}-{val_loss:.2f}.ckpt', save_weights_only=True, save_best_only = True , verbose= 1),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='../data/logs'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/60 [======>.......................] - ETA: 4:23 - loss: 212.7419"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\steli\\DeepLearning\\Project\\dl_omr\\notebooks\\ctc_model_fit_New_perspective.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000020?line=1'>2</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000020?line=3'>4</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000020?line=4'>5</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000020?line=5'>6</a>\u001b[0m     train_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000020?line=6'>7</a>\u001b[0m     \u001b[39m# tf.compat.v1.data.make_one_shot_iterator(train_dataset).get_next(),\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000020?line=7'>8</a>\u001b[0m     \u001b[39m# validation_data = tf.compat.v1.data.make_one_shot_iterator(validation_dataset).get_next(),\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000020?line=8'>9</a>\u001b[0m     validation_data \u001b[39m=\u001b[39;49m validation_dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000020?line=9'>10</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000020?line=10'>11</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mmy_callbacks\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000020?line=11'>12</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the number of epochs.\n",
    "epochs = 50\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    # tf.compat.v1.data.make_one_shot_iterator(train_dataset).get_next(),\n",
    "    # validation_data = tf.compat.v1.data.make_one_shot_iterator(validation_dataset).get_next(),\n",
    "    validation_data = validation_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=my_callbacks\n",
    ")\n",
    "# model.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_weights(\"../models/model_50epoch.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x19154883fd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "# model.load_weights(\"../models/model_1epoch.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = tf.keras.models.load_model('../models/model.01-105.60.h5', custom_objects={'CTCLayer': CTCLayer})\n",
    "# new_model = tf.keras.models.load_model('../models/model_1epoch.hdf5', custom_objects={'CTCLayer': CTCLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Model\n",
    "# model = tf.keras.models.load_model('../models/model.01-105.60.h5', custom_objects={'CTCLayer': CTCLayer})\n",
    "# Loading Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting using loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_decoder(preds):\n",
    "    pred_indcies = np.argmax(preds, axis=2)\n",
    "    decoded_pred = data_obj.decode_seqs(pred_indcies)\n",
    "    return decoded_pred\n",
    "\n",
    "def ground_truth_decoder(truth):\n",
    "    return data_obj.decode_seqs(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clef-C1\tkeySignature-EbM\ttimeSignature-2/4\tmultirest-23\tbarline\trest-quarter\trest-eighth\tnote-Bb4_eighth\tbarline\tnote-Bb4_quarter.\tnote-G4_eighth\tbarline\tnote-Eb5_quarter.\tnote-D5_eighth\tbarline\tnote-C5_eighth\tnote-C5_eighth\trest-quarter\tbarline\n"
     ]
    }
   ],
   "source": [
    "ground_truth = lst_test[\"text\"]\n",
    "print(ground_truth_decoder(ground_truth)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline',\n",
       " 'barline']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(test_dataset)\n",
    "pred_strings = ctc_decoder(preds)\n",
    "pred_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clef-C1\tkeySignature-EbM\ttimeSignature-2/4\tmultirest-23\tbarline\trest-quarter\trest-eighth\tnote-Bb4_eighth\tbarline\tnote-Bb4_quarter.\tnote-G4_eighth\tbarline\tnote-Eb5_quarter.\tnote-D5_eighth\tbarline\tnote-C5_eighth\tnote-C5_eighth\trest-quarter\tbarline\n",
      "\n",
      " barline\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_predict(lst_test,pred_strings, index):\n",
    "    images = lst_test[\"images\"][index]\n",
    "    ground_truth = lst_test[\"text\"]\n",
    "    ground_truth = ground_truth_decoder(ground_truth)[index]\n",
    "    # [index]\n",
    "    predictions = pred_strings[index]\n",
    "    plot = cv2.imread(images)\n",
    "    plt.imshow(plot)\n",
    "    plt.show()\n",
    "    print(ground_truth)\n",
    "    print(\"\\n\",predictions)\n",
    "    # return plot\n",
    "\n",
    "plot_predict(lst_test,pred_strings, 0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9bbe03f6c4bbdf56f443191d16980388af1b731aba7be9951b0256cee325895"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
