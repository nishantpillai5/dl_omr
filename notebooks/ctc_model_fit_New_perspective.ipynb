{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://keras.io/examples/audio/ctc_asr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Layer\n",
    "# from tensorflow.keras.layers import Input, Dense, Activation, LeakyReLU, Permute, Bidirectional\n",
    "# from tensorflow.keras.layers import Reshape, Lambda, BatchNormalization, LSTM\n",
    "# from tensorflow.python.keras.layers.merge import add, concatenate\n",
    "# from tensorflow.python.keras.layers.recurrent import LSTM\n",
    "# from tensorflow.keras.layers import CuDNNLSTM\n",
    "from primus import CTC_PriMuS\n",
    "import ctc_utils\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_model_params(img_height, vocabulary_size):\n",
    "    params = dict()\n",
    "    params['img_height'] = img_height\n",
    "    params['img_width'] = None\n",
    "    params['batch_size'] = 16\n",
    "    params['img_channels'] = 1\n",
    "    params['conv_blocks'] = 2\n",
    "    params['conv_filter_n'] = [32, 64]\n",
    "    params['conv_filter_size'] = [ [3,3], [3,3] ]\n",
    "    params['conv_pooling_size'] = [ [2,2], [2,2] ]\n",
    "    params['rnn_units'] = 32\n",
    "    params['rnn_layers'] = 1\n",
    "    params['vocabulary_size'] = vocabulary_size\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = K.ctc_batch_cost\n",
    "        # self.loss_fn = K.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\") # 16\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        # print(\"Y_pred shape:  \",y_pred.shape)\n",
    "        # print(\"Y_true shape:  \",y_true.shape)\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "def buildModel(params, input_width, rnn_layers = 2, rnn_units = 128):\n",
    "    input_shape = (params['img_height'],params['img_width'], params['img_channels'])\n",
    "\n",
    "    inputs = layers.Input(type_spec=tf.TensorSpec(shape=[None, params['img_height'], input_width, 1], dtype=tf.float32), name = \"image\" )\n",
    "    # inputs = layers.Input(name='image', shape=input_shape, dtype='float32')\n",
    "\n",
    "    labels = layers.Input(type_spec=tf.TensorSpec(shape=[None, None], dtype=tf.float32), name = \"label\" )\n",
    "    # x = layers.Reshape((params['img_height'], input_width, 1), name=\"expand_dim\")(inputs)\n",
    "    x = layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size= [params['conv_filter_n'][0], params['conv_filter_n'][0]],\n",
    "        strides=[2, 2],\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"conv_1\",\n",
    "    )(inputs)\n",
    "    x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n",
    "    x = layers.ReLU(name=\"conv_1_relu\")(x)\n",
    "    x = layers.MaxPool2D(pool_size=params['conv_pooling_size'][0], strides = params['conv_pooling_size'][0], name='max1')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=[params['conv_filter_n'][1], params['conv_filter_n'][1]],\n",
    "        strides=[1, 2],\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"conv_2\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n",
    "    x = layers.ReLU(name=\"conv_2_relu\")(x)\n",
    "    x = layers.MaxPool2D(pool_size=params['conv_pooling_size'][1], strides = params['conv_pooling_size'][1], name='max2')(x)\n",
    "    print(x.shape)\n",
    "    x = layers.Reshape((-1, x.shape[-3] * x.shape[-1]))(x)\n",
    "\n",
    "    for i in range(1, rnn_layers + 1):\n",
    "        recurrent = layers.GRU(\n",
    "            units=rnn_units,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            use_bias=True,\n",
    "            return_sequences=True,\n",
    "            reset_after=True,\n",
    "            name=f\"gru_{i}\",\n",
    "        )\n",
    "        x = layers.Bidirectional(\n",
    "            recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\"\n",
    "        )(x)\n",
    "        if i < rnn_layers:\n",
    "            x = layers.Dropout(rate=0.5)(x)\n",
    "\n",
    "    num_classes = params['vocabulary_size'] + 1\n",
    "    y_pred = layers.Dense(num_classes, kernel_initializer='he_normal',name='dense2', activation='softmax')(x) #(None, 32, 63)        \n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, y_pred)\n",
    "    model = Model([inputs,labels], output, name=\"OMR\")\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "    model.compile(optimizer = optimizer)\n",
    "    # model.compile(optimizer=opt, loss=CTCLoss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 800 and validating with 200\n"
     ]
    }
   ],
   "source": [
    "img_height = 64\n",
    "corpus_dirpath = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/primusCalvoRizoAppliedSciences2018/\"\n",
    "corpus_filepath = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/train.txt\"\n",
    "dictionary_path = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/vocabulary_semantic.txt\"\n",
    "test_set_path = \"C:/Users/steli/DeepLearning/Project/tf-end-to-end/Data/test.txt\"\n",
    "# Here\n",
    "# primus = CTC_PriMuS(corpus_dirpath,corpus_filepath,dictionary_path, True, val_split = 0.2)\n",
    "\n",
    "# corpus_dirpath = \"/content/primusCalvoRizoAppliedSciences2018/\"\n",
    "# corpus_filepath = \"/content/train.txt\"\n",
    "# dictionary_path = \"/content/vocabulary_semantic.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "image_paths = []\n",
    "image_texts = []\n",
    "\n",
    "class PriMuS_Data:\n",
    "    def __init__(self, corpus_dirpath, corpus_filepath, dictionary_path):\n",
    "        self.corpus_dirpath = corpus_dirpath\n",
    "\n",
    "        # Corpus\n",
    "        corpus_file = open(corpus_filepath,'r')\n",
    "        self.corpus_list = corpus_file.read().splitlines()\n",
    "        corpus_file.close()\n",
    "\n",
    "        self.current_idx = 0\n",
    "\n",
    "        # Dictionary\n",
    "        self.word2int = {}\n",
    "        self.int2word = {}\n",
    "            \n",
    "        dict_file = open(dictionary_path,'r')\n",
    "        dict_list = dict_file.read().splitlines()\n",
    "        for word in dict_list:\n",
    "            if not word in self.word2int:\n",
    "                word_idx = len(self.word2int)\n",
    "                self.word2int[word] = word_idx\n",
    "                self.int2word[word_idx] = word\n",
    "\n",
    "        dict_file.close()\n",
    "\n",
    "        self.vocabulary_size = len(self.word2int)\n",
    "    \n",
    "    def get_vocabulary_size(self):\n",
    "        return self.vocabulary_size\n",
    "        \n",
    "    def get_data(self):\n",
    "        return self.corpus_list\n",
    "\n",
    "    def encode_seqs(self, seqs):\n",
    "        encoded = []\n",
    "        for seq in seqs:\n",
    "            new_seq=[]\n",
    "            for sym in seq:\n",
    "                new_seq.append(self.word2int[sym])\n",
    "            encoded.append(new_seq)\n",
    "        return encoded\n",
    "\n",
    "    def decode_seqs(self, seqs): # [1,2,3,4,..] -> \"clef\\tC-note\"\n",
    "        decoded = []\n",
    "        for seq in seqs:\n",
    "            new_seq=\"\"\n",
    "            for sym in seq:\n",
    "                new_seq+= self.int2word[sym] + \"\\t\"\n",
    "            new_seq = new_seq[:-1]\n",
    "            decoded.append(new_seq)\n",
    "        return decoded\n",
    "\n",
    "    def get_test(self):\n",
    "        obj = self.trim_ds(val_split=1) \n",
    "        return {\"images\": obj['train']['images'], \"text\":obj['train']['text']}\n",
    "\n",
    "    def trim_ds(self, val_split = 0.9):\n",
    "        folder_path = self.corpus_dirpath\n",
    "        list_of_files = self.corpus_list #10,000 filenames\n",
    "\n",
    "        image_paths = [self.corpus_dirpath+f\"{x}/{x}.png\" for x in self.corpus_list] # list of image paths\n",
    "        text_paths = [self.corpus_dirpath+f\"{x}/{x}.semantic\" for x in self.corpus_list]\n",
    "\n",
    "        image_texts = [] # list of strings\n",
    "\n",
    "        for path in text_paths:\n",
    "            with open(path, \"r\") as file:\n",
    "                image_texts.append(file.readline().split())\n",
    "\n",
    "        image_texts = self.encode_seqs(image_texts)\n",
    "\n",
    "        max_label_len = max([len(seq) for seq in image_texts])\n",
    "        print(max_label_len)\n",
    "        padded_image_texts = pad_sequences(image_texts, maxlen=max_label_len, padding='post', value= self.vocabulary_size + 1)\n",
    "\n",
    "        # TODO: do line 17 from the link : https://github.com/rajesh-bhat/spark-ai-summit-2020-text-extraction/blob/master/CRNN_CTC_wandb.ipynb\n",
    "\n",
    "        # TODO: Use self.word2int to encode each element of the lists in image_texts\n",
    "        # Input image_texts = [  ['clef','C-note'] , [.......], ....]\n",
    "        # Final image_texts = [  [5,3] , [.......], ....]\n",
    "        # if 'clef' == 5, 'C-note' == 3 in word2int dictionary\n",
    "        # Also add padding using the function below so length of each element is consistent\n",
    "\n",
    "        # from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "        # padded_image_texts = list(map(encode_to_labels, image_texts))\n",
    "        # padded_image_texts[0]\n",
    "\n",
    "\n",
    "        train_image_paths = image_paths[ : int(len(image_paths) * val_split)]\n",
    "        train_image_texts = padded_image_texts[ : int(len(padded_image_texts) * val_split)]\n",
    "\n",
    "        val_image_paths = image_paths[int(len(image_paths) * val_split) : ]\n",
    "        val_image_texts = padded_image_texts[int(len(padded_image_texts) * val_split) : ]\n",
    "\n",
    "        return {\"train\":{\"images\":train_image_paths, \"text\": train_image_texts}, \"val\":{\"images\":val_image_paths, \"text\": val_image_texts}}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "data_obj = PriMuS_Data(corpus_dirpath, corpus_filepath, dictionary_path)\n",
    "lst = data_obj.trim_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "data_obj_test = PriMuS_Data(corpus_dirpath, test_set_path, dictionary_path)\n",
    "lst_test = data_obj_test.get_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images to desired dimensions with unknown width\n",
    "def resize_no_width(image, height):\n",
    "    width = int(float(height * image.shape[1]) / image.shape[0])\n",
    "    sample_img = cv2.resize(image, (width, height))\n",
    "    return sample_img\n",
    "\n",
    "\n",
    "# Pre-process a single image sample(resize/normalize/max_width resize)\n",
    "def process_single_sample(img_path, label,max_width = 30):\n",
    "    params = default_model_params(img_height,primus.vocabulary_size)\n",
    "    # 1. Read image\n",
    "    img = tf.io.read_file(img_path)\n",
    "    # 2. Decode and convert to grayscale\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    # 3. Convert to float32 in [0, 1] range\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # 4. Resize to the desired size\n",
    "    img = tf.image.resize(img,[params['img_height'], max_width])\n",
    "    # TODO: Get height from params, calculate width from max of all images\n",
    "    return {\"image\": img, \"label\": label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003\n",
      "(None, 8, 125, 64)\n",
      "Model: \"OMR\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image (InputLayer)             [(None, 64, 2003, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv_1 (Conv2D)                (None, 32, 1002, 32  32768       ['image[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_1_bn (BatchNormalization)  (None, 32, 1002, 32  128        ['conv_1[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_1_relu (ReLU)             (None, 32, 1002, 32  0           ['conv_1_bn[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max1 (MaxPooling2D)            (None, 16, 501, 32)  0           ['conv_1_relu[0][0]']            \n",
      "                                                                                                  \n",
      " conv_2 (Conv2D)                (None, 16, 251, 64)  8388608     ['max1[0][0]']                   \n",
      "                                                                                                  \n",
      " conv_2_bn (BatchNormalization)  (None, 16, 251, 64)  256        ['conv_2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_2_relu (ReLU)             (None, 16, 251, 64)  0           ['conv_2_bn[0][0]']              \n",
      "                                                                                                  \n",
      " max2 (MaxPooling2D)            (None, 8, 125, 64)   0           ['conv_2_relu[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 125, 512)     0           ['max2[0][0]']                   \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 125, 256)    493056      ['reshape_1[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 125, 256)     0           ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 125, 256)    296448      ['dropout_1[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 125, 1782)    457974      ['bidirectional_2[0][0]']        \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)            (None, 125, 1782)    0           ['label[0][0]',                  \n",
      "                                                                  'dense2[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,669,238\n",
      "Trainable params: 9,669,046\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "\n",
    "image_widths = [cv2.imread(img).shape[1] for img in lst[\"train\"][\"images\"]]\n",
    "image_widths_2 = [cv2.imread(img).shape[1] for img in lst[\"val\"][\"images\"]]\n",
    "image_widths_3 = [cv2.imread(img).shape[1] for img in lst[\"train\"][\"images\"]]\n",
    "\n",
    "max_image_width = max(image_widths + image_widths_2 + image_widths_3)\n",
    "\n",
    "print(max_image_width)\n",
    "# Parameterization\n",
    "img_height = 64\n",
    "params = default_model_params(img_height,data_obj.vocabulary_size)\n",
    "max_epochs = 100\n",
    "dropout = 0.5\n",
    "# Model\n",
    "model = buildModel(params,input_width = max_image_width)\n",
    "model.summary()\n",
    "\n",
    "# Pre-process a single image sample(resize/normalize/max_width resize)\n",
    "def process_single_sample(img_path, label):\n",
    "    params = default_model_params(img_height,data_obj.vocabulary_size)\n",
    "    # 1. Read image\n",
    "    img = tf.io.read_file(img_path)\n",
    "    # 2. Decode and convert to grayscale\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    # 3. Convert to float32 in [0, 1] range\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # 4. Resize to the desired size\n",
    "    img = tf.image.resize(img,[params['img_height'], max_image_width])\n",
    "    # TODO: Get height from params, calculate width from max of all images\n",
    "    return {\"image\": img, \"label\": label}\n",
    "# train_dataset = train_dataset.map(process_single_sample(max_width = max_image_width))\n",
    "\n",
    "# processed_images = [process_single_sample(img,label,max_image_width) for img,label in zip(lst[\"train\"][\"images\"], lst[\"train\"][\"text\"])]\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((lst['train']['images'], lst['train']['text']))\n",
    "\n",
    "# train_dataset = (\n",
    "#     train_dataset.map(\n",
    "#         process_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "#     )\n",
    "#     .batch(batch_size)\n",
    "#     .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "# )\n",
    "\n",
    "# validation_dataset = tf.data.Dataset.from_tensor_slices((lst['val']['images'], lst['val']['text']))\n",
    "# validation_dataset = (\n",
    "#     validation_dataset.map(\n",
    "#         process_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "#     )\n",
    "#     .batch(batch_size)\n",
    "#     .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "# )\n",
    "def tfdata_generator_train(batch_size= 16):\n",
    "  '''Construct a data generator using `tf.Dataset`. '''\n",
    "  train_dataset = tf.data.Dataset.from_tensor_slices((lst['train']['images'], lst['train']['text']))\n",
    "  train_dataset = train_dataset.map(process_single_sample)\n",
    "  train_dataset = train_dataset.batch(batch_size)\n",
    "  # train_dataset = train_dataset.repeat()\n",
    "  train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "  return train_dataset\n",
    "\n",
    "def tfdata_generator_val(batch_size= 16):\n",
    "  '''Construct a data generator using `tf.Dataset`. '''\n",
    "  val_dataset = tf.data.Dataset.from_tensor_slices((lst['val']['images'], lst['val']['text']))\n",
    "  val_dataset = val_dataset.map(process_single_sample)\n",
    "  val_dataset = val_dataset.batch(batch_size)\n",
    "  # val_dataset = val_dataset.repeat()\n",
    "  val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "  return val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tfdata_generator_train()\n",
    "validation_dataset = tfdata_generator_val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec={'image': TensorSpec(shape=(None, 64, 2003, 1), dtype=tf.float32, name=None), 'label': TensorSpec(shape=(None, 56), dtype=tf.int32, name=None)}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='../models/model.{epoch:02d}-{val_loss:.2f}.ckpt', save_weights_only=True, verbose= 1),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='../data/logs'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of epochs.\n",
    "epochs = 1\n",
    "\n",
    "# Train the model\n",
    "# history = model.fit(\n",
    "#     train_dataset,\n",
    "#     # tf.compat.v1.data.make_one_shot_iterator(train_dataset).get_next(),\n",
    "#     # validation_data = tf.compat.v1.data.make_one_shot_iterator(validation_dataset).get_next(),\n",
    "#     validation_data = validation_dataset,\n",
    "#     epochs=epochs,\n",
    "#     callbacks=my_callbacks\n",
    "# )\n",
    "# model.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('../models/model_1epoch.hdf5')\n",
    "# This\n",
    "# model.save_weights(\"../models/model_1epoch.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x22ad27446d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"../models/model_1epoch.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CTCLayer.__init__() got an unexpected keyword argument 'trainable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\steli\\DeepLearning\\Project\\dl_omr\\notebooks\\ctc_model_fit_New_perspective.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000018?line=0'>1</a>\u001b[0m \u001b[39m# new_model = tf.keras.models.load_model('../models/model.01-105.60.h5', custom_objects={'CTCLayer': CTCLayer})\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000018?line=1'>2</a>\u001b[0m new_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39m../models/model_1epoch.hdf5\u001b[39;49m\u001b[39m'\u001b[39;49m, custom_objects\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mCTCLayer\u001b[39;49m\u001b[39m'\u001b[39;49m: CTCLayer})\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py:796\u001b[0m, in \u001b[0;36mLayer.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=779'>780</a>\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=780'>781</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_config\u001b[39m(\u001b[39mcls\u001b[39m, config):\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=781'>782</a>\u001b[0m   \u001b[39m\"\"\"Creates a layer from its config.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=782'>783</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=783'>784</a>\u001b[0m \u001b[39m  This method is the reverse of `get_config`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=793'>794</a>\u001b[0m \u001b[39m      A layer instance.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=794'>795</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=795'>796</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n",
      "\u001b[1;31mTypeError\u001b[0m: CTCLayer.__init__() got an unexpected keyword argument 'trainable'"
     ]
    }
   ],
   "source": [
    "# new_model = tf.keras.models.load_model('../models/model.01-105.60.h5', custom_objects={'CTCLayer': CTCLayer})\n",
    "# new_model = tf.keras.models.load_model('../models/model_1epoch.hdf5', custom_objects={'CTCLayer': CTCLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CTCLayer.__init__() got an unexpected keyword argument 'trainable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\steli\\DeepLearning\\Project\\dl_omr\\notebooks\\ctc_model_fit_New_perspective.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000016?line=0'>1</a>\u001b[0m \u001b[39m# Retrieve the config\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000016?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39m../models/model.01-105.60.h5\u001b[39;49m\u001b[39m'\u001b[39;49m, custom_objects\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mCTCLayer\u001b[39;49m\u001b[39m'\u001b[39;49m: CTCLayer})\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\steli\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py:796\u001b[0m, in \u001b[0;36mLayer.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=779'>780</a>\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=780'>781</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_config\u001b[39m(\u001b[39mcls\u001b[39m, config):\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=781'>782</a>\u001b[0m   \u001b[39m\"\"\"Creates a layer from its config.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=782'>783</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=783'>784</a>\u001b[0m \u001b[39m  This method is the reverse of `get_config`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=793'>794</a>\u001b[0m \u001b[39m      A layer instance.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=794'>795</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/steli/.conda/envs/tf-gpu/lib/site-packages/keras/engine/base_layer.py?line=795'>796</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n",
      "\u001b[1;31mTypeError\u001b[0m: CTCLayer.__init__() got an unexpected keyword argument 'trainable'"
     ]
    }
   ],
   "source": [
    "# Loading Model\n",
    "# model = tf.keras.models.load_model('../models/model.01-105.60.h5', custom_objects={'CTCLayer': CTCLayer})\n",
    "# Loading Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting using loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec={'image': TensorSpec(shape=(None, 64, 2003, 1), dtype=tf.float32, name=None), 'label': TensorSpec(shape=(None, 37), dtype=tf.int32, name=None)}>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfdata_generator_test(batch_size= 16):\n",
    "  '''Construct a data generator using `tf.Dataset`. '''\n",
    "  test_dataset = tf.data.Dataset.from_tensor_slices((lst_test['train']['images'], lst_test['train']['text']))\n",
    "  test_dataset = test_dataset.map(process_single_sample)\n",
    "  test_dataset = test_dataset.batch(batch_size)\n",
    "  # train_dataset = train_dataset.repeat()\n",
    "  test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "  return test_dataset\n",
    "\n",
    "test_dataset = tfdata_generator_test()\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.11838069e-03, 7.71671012e-02, 2.58293061e-04, ...,\n",
       "         3.78101133e-02, 3.38348141e-03, 3.96550357e-01],\n",
       "        [8.45778035e-04, 6.00359356e-03, 7.48274833e-05, ...,\n",
       "         2.60984618e-02, 2.47637252e-03, 8.09604526e-01],\n",
       "        [7.29619002e-04, 1.89886312e-03, 4.28396343e-05, ...,\n",
       "         2.14035679e-02, 2.04662140e-03, 8.81747782e-01],\n",
       "        ...,\n",
       "        [1.41756073e-01, 1.04811596e-04, 5.81863333e-06, ...,\n",
       "         2.41984002e-04, 6.68568391e-05, 7.51188755e-01],\n",
       "        [2.67553896e-01, 1.13861563e-04, 7.23577250e-06, ...,\n",
       "         2.59026012e-04, 9.10391318e-05, 6.06946111e-01],\n",
       "        [5.56661487e-01, 1.10371897e-04, 9.63502316e-06, ...,\n",
       "         2.31698970e-04, 1.21286539e-04, 3.04439873e-01]],\n",
       "\n",
       "       [[1.07852672e-03, 7.90011585e-02, 2.63779541e-04, ...,\n",
       "         3.85493562e-02, 3.45807197e-03, 3.83268297e-01],\n",
       "        [8.52354453e-04, 6.02231920e-03, 7.56754307e-05, ...,\n",
       "         2.66711786e-02, 2.57882080e-03, 8.06567848e-01],\n",
       "        [7.22717959e-04, 1.91432727e-03, 4.39928372e-05, ...,\n",
       "         2.16986258e-02, 2.09696521e-03, 8.80994141e-01],\n",
       "        ...,\n",
       "        [1.42918587e-01, 1.07110871e-04, 5.86611623e-06, ...,\n",
       "         2.35982268e-04, 6.68467183e-05, 7.49875426e-01],\n",
       "        [2.67959177e-01, 1.15993113e-04, 7.28078339e-06, ...,\n",
       "         2.50819605e-04, 8.98956932e-05, 6.06188118e-01],\n",
       "        [5.54707289e-01, 1.12748239e-04, 9.78817752e-06, ...,\n",
       "         2.27720753e-04, 1.20852354e-04, 3.05624247e-01]],\n",
       "\n",
       "       [[1.05834671e-03, 8.08258280e-02, 2.66096147e-04, ...,\n",
       "         3.91039066e-02, 3.71569069e-03, 3.58280391e-01],\n",
       "        [8.69667449e-04, 6.08839886e-03, 7.70608603e-05, ...,\n",
       "         2.72268150e-02, 2.73598055e-03, 8.02024126e-01],\n",
       "        [7.21517194e-04, 1.88326102e-03, 4.29023021e-05, ...,\n",
       "         2.12062355e-02, 2.07476038e-03, 8.83704841e-01],\n",
       "        ...,\n",
       "        [1.40139416e-01, 1.03625207e-04, 5.73833813e-06, ...,\n",
       "         2.47084768e-04, 6.99286029e-05, 7.53691792e-01],\n",
       "        [2.68564135e-01, 1.13468202e-04, 7.19591617e-06, ...,\n",
       "         2.60127679e-04, 9.43330961e-05, 6.05721533e-01],\n",
       "        [5.57802081e-01, 1.09986417e-04, 9.75550211e-06, ...,\n",
       "         2.31626123e-04, 1.24493730e-04, 3.03165287e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.04398979e-03, 7.75276721e-02, 2.68454576e-04, ...,\n",
       "         3.75149138e-02, 3.53032048e-03, 3.76937091e-01],\n",
       "        [7.97635934e-04, 5.33036795e-03, 7.25026766e-05, ...,\n",
       "         2.41143070e-02, 2.32866639e-03, 8.23657632e-01],\n",
       "        [6.70063833e-04, 1.51228346e-03, 3.72388495e-05, ...,\n",
       "         1.78034008e-02, 1.67879404e-03, 9.00885224e-01],\n",
       "        ...,\n",
       "        [1.37769744e-01, 1.05941843e-04, 5.67957431e-06, ...,\n",
       "         2.46868673e-04, 7.31889086e-05, 7.57633567e-01],\n",
       "        [2.59858757e-01, 1.16749106e-04, 7.20670050e-06, ...,\n",
       "         2.59110151e-04, 9.79299730e-05, 6.14955425e-01],\n",
       "        [5.41267216e-01, 1.16225347e-04, 1.02434342e-05, ...,\n",
       "         2.37553482e-04, 1.29783191e-04, 3.15130889e-01]],\n",
       "\n",
       "       [[1.14080426e-03, 7.45442435e-02, 2.53719423e-04, ...,\n",
       "         3.74251008e-02, 3.33229266e-03, 4.09971654e-01],\n",
       "        [8.31560406e-04, 5.79451583e-03, 7.31553664e-05, ...,\n",
       "         2.49250419e-02, 2.36980361e-03, 8.16089272e-01],\n",
       "        [7.23704055e-04, 1.91174797e-03, 4.23214115e-05, ...,\n",
       "         2.08321959e-02, 1.99798611e-03, 8.83563638e-01],\n",
       "        ...,\n",
       "        [1.43229440e-01, 9.98444593e-05, 5.90384570e-06, ...,\n",
       "         2.45173549e-04, 6.28843918e-05, 7.47485399e-01],\n",
       "        [2.73672700e-01, 1.09592533e-04, 7.20756088e-06, ...,\n",
       "         2.59740074e-04, 8.61125081e-05, 5.98670065e-01],\n",
       "        [5.65048575e-01, 1.07820983e-04, 9.33969659e-06, ...,\n",
       "         2.33283325e-04, 1.18649463e-04, 2.96936899e-01]],\n",
       "\n",
       "       [[1.03894656e-03, 7.73503780e-02, 2.67380878e-04, ...,\n",
       "         3.79227474e-02, 3.51742515e-03, 3.75305653e-01],\n",
       "        [8.16440093e-04, 5.33111626e-03, 7.15441493e-05, ...,\n",
       "         2.49811392e-02, 2.40622810e-03, 8.19570422e-01],\n",
       "        [6.78090903e-04, 1.55273988e-03, 3.78121076e-05, ...,\n",
       "         1.86941978e-02, 1.75554771e-03, 8.97454143e-01],\n",
       "        ...,\n",
       "        [1.40695378e-01, 1.08303859e-04, 5.83060137e-06, ...,\n",
       "         2.41947870e-04, 7.19004311e-05, 7.53184736e-01],\n",
       "        [2.59554625e-01, 1.16337382e-04, 7.17085595e-06, ...,\n",
       "         2.61536159e-04, 9.83734280e-05, 6.16742373e-01],\n",
       "        [5.44390321e-01, 1.16566771e-04, 1.00451816e-05, ...,\n",
       "         2.33256636e-04, 1.28975502e-04, 3.13658983e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(test_dataset)\n",
    "# FIXME: Hardcoded validation split\n",
    "# pred_texts = ctc_decoder(preds)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 125, 1782)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_indcies = np.argmax(preds, axis=2)\n",
    "pred_indcies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781,\n",
       "       1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781,\n",
       "       1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781,\n",
       "       1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781,\n",
       "       1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781,\n",
       "       1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781,\n",
       "       1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781,\n",
       "       1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781,\n",
       "       1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781,\n",
       "       1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781,\n",
       "       1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781, 1781,\n",
       "       1781, 1781, 1781,    0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_indcies[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1781"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obj.vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1781"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['vocabulary_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data_obj.word2int.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'barline': 0,\n",
       " 'clef-C1': 1,\n",
       " 'clef-C2': 2,\n",
       " 'clef-C3': 3,\n",
       " 'clef-C4': 4,\n",
       " 'clef-C5': 5,\n",
       " 'clef-F3': 6,\n",
       " 'clef-F4': 7,\n",
       " 'clef-F5': 8,\n",
       " 'clef-G1': 9,\n",
       " 'clef-G2': 10,\n",
       " 'gracenote-A2_eighth': 11,\n",
       " 'gracenote-A2_quarter': 12,\n",
       " 'gracenote-A2_sixteenth': 13,\n",
       " 'gracenote-A#3_eighth': 14,\n",
       " 'gracenote-A3_eighth': 15,\n",
       " 'gracenote-A3_half': 16,\n",
       " 'gracenote-A3_quarter': 17,\n",
       " 'gracenote-A#3_sixteenth': 18,\n",
       " 'gracenote-A3_sixteenth': 19,\n",
       " 'gracenote-A3_thirty_second': 20,\n",
       " 'gracenote-A#4_eighth': 21,\n",
       " 'gracenote-A4_eighth': 22,\n",
       " 'gracenote-A#4_half': 23,\n",
       " 'gracenote-A4_half': 24,\n",
       " 'gracenote-A#4_quarter': 25,\n",
       " 'gracenote-A4_quarter': 26,\n",
       " 'gracenote-A#4_sixteenth': 27,\n",
       " 'gracenote-A4_sixteenth': 28,\n",
       " 'gracenote-A#4_thirty_second': 29,\n",
       " 'gracenote-A4_thirty_second': 30,\n",
       " 'gracenote-A#5_eighth': 31,\n",
       " 'gracenote-A5_eighth': 32,\n",
       " 'gracenote-A5_quarter': 33,\n",
       " 'gracenote-A5_sixteenth': 34,\n",
       " 'gracenote-A5_sixteenth.': 35,\n",
       " 'gracenote-A5_thirty_second': 36,\n",
       " 'gracenote-Ab3_double_whole': 37,\n",
       " 'gracenote-Ab3_eighth': 38,\n",
       " 'gracenote-Ab3_sixteenth': 39,\n",
       " 'gracenote-Ab3_thirty_second': 40,\n",
       " 'gracenote-Ab4_eighth': 41,\n",
       " 'gracenote-Ab4_half': 42,\n",
       " 'gracenote-Ab4_quarter': 43,\n",
       " 'gracenote-Ab4_sixteenth': 44,\n",
       " 'gracenote-Ab4_thirty_second': 45,\n",
       " 'gracenote-Ab5_eighth': 46,\n",
       " 'gracenote-Ab5_quarter': 47,\n",
       " 'gracenote-Ab5_sixteenth': 48,\n",
       " 'gracenote-Ab5_thirty_second': 49,\n",
       " 'gracenote-B2_sixteenth': 50,\n",
       " 'gracenote-B3_eighth': 51,\n",
       " 'gracenote-B3_quarter': 52,\n",
       " 'gracenote-B#3_sixteenth': 53,\n",
       " 'gracenote-B3_sixteenth': 54,\n",
       " 'gracenote-B3_thirty_second': 55,\n",
       " 'gracenote-B#4_eighth': 56,\n",
       " 'gracenote-B4_eighth': 57,\n",
       " 'gracenote-B#4_quarter': 58,\n",
       " 'gracenote-B4_quarter': 59,\n",
       " 'gracenote-B#4_sixteenth': 60,\n",
       " 'gracenote-B4_sixteenth': 61,\n",
       " 'gracenote-B4_sixteenth.': 62,\n",
       " 'gracenote-B4_thirty_second': 63,\n",
       " 'gracenote-B5_eighth': 64,\n",
       " 'gracenote-Bb3_eighth': 65,\n",
       " 'gracenote-Bb3_quarter': 66,\n",
       " 'gracenote-Bb3_sixteenth': 67,\n",
       " 'gracenote-Bb3_thirty_second': 68,\n",
       " 'gracenote-Bb4_eighth': 69,\n",
       " 'gracenote-Bb4_eighth.': 70,\n",
       " 'gracenote-Bb4_half': 71,\n",
       " 'gracenote-Bb4_quarter': 72,\n",
       " 'gracenote-Bb4_sixteenth': 73,\n",
       " 'gracenote-Bb4_thirty_second': 74,\n",
       " 'gracenote-Bb5_eighth': 75,\n",
       " 'gracenote-C#3_eighth': 76,\n",
       " 'gracenote-C3_eighth': 77,\n",
       " 'gracenote-C3_quarter': 78,\n",
       " 'gracenote-C#3_sixteenth': 79,\n",
       " 'gracenote-C3_sixteenth': 80,\n",
       " 'gracenote-C#4_eighth': 81,\n",
       " 'gracenote-C#4_eighth.': 82,\n",
       " 'gracenote-C4_eighth': 83,\n",
       " 'gracenote-C#4_quarter': 84,\n",
       " 'gracenote-C4_quarter': 85,\n",
       " 'gracenote-C#4_sixteenth': 86,\n",
       " 'gracenote-C4_sixteenth': 87,\n",
       " 'gracenote-C#4_thirty_second': 88,\n",
       " 'gracenote-C4_thirty_second': 89,\n",
       " 'gracenote-C#5_eighth': 90,\n",
       " 'gracenote-C#5_eighth.': 91,\n",
       " 'gracenote-C5_eighth': 92,\n",
       " 'gracenote-C#5_half': 93,\n",
       " 'gracenote-C5_half': 94,\n",
       " 'gracenote-C#5_quarter': 95,\n",
       " 'gracenote-C5_quarter': 96,\n",
       " 'gracenote-C#5_sixteenth': 97,\n",
       " 'gracenote-C#5_sixteenth.': 98,\n",
       " 'gracenote-C5_sixteenth': 99,\n",
       " 'gracenote-C#5_thirty_second': 100,\n",
       " 'gracenote-C5_thirty_second': 101,\n",
       " 'gracenote-Cb5_eighth': 102,\n",
       " 'gracenote-Cb5_quarter': 103,\n",
       " 'gracenote-Cb5_thirty_second': 104,\n",
       " 'gracenote-D3_eighth': 105,\n",
       " 'gracenote-D#3_quarter': 106,\n",
       " 'gracenote-D3_quarter': 107,\n",
       " 'gracenote-D#3_sixteenth': 108,\n",
       " 'gracenote-D3_sixteenth': 109,\n",
       " 'gracenote-D#4_eighth': 110,\n",
       " 'gracenote-D4_eighth': 111,\n",
       " 'gracenote-D#4_quarter': 112,\n",
       " 'gracenote-D4_quarter': 113,\n",
       " 'gracenote-D#4_sixteenth': 114,\n",
       " 'gracenote-D4_sixteenth': 115,\n",
       " 'gracenote-D#4_thirty_second': 116,\n",
       " 'gracenote-D4_thirty_second': 117,\n",
       " 'gracenote-D#5_eighth': 118,\n",
       " 'gracenote-D5_eighth': 119,\n",
       " 'gracenote-D5_half': 120,\n",
       " 'gracenote-D#5_quarter': 121,\n",
       " 'gracenote-D5_quarter': 122,\n",
       " 'gracenote-D#5_sixteenth': 123,\n",
       " 'gracenote-D5_sixteenth': 124,\n",
       " 'gracenote-D5_sixteenth.': 125,\n",
       " 'gracenote-D#5_thirty_second': 126,\n",
       " 'gracenote-D5_thirty_second': 127,\n",
       " 'gracenote-Db4_eighth': 128,\n",
       " 'gracenote-Db4_sixteenth': 129,\n",
       " 'gracenote-Db5_eighth': 130,\n",
       " 'gracenote-Db5_half': 131,\n",
       " 'gracenote-Db5_quarter': 132,\n",
       " 'gracenote-Db5_sixteenth': 133,\n",
       " 'gracenote-Db5_thirty_second': 134,\n",
       " 'gracenote-E3_eighth': 135,\n",
       " 'gracenote-E3_quarter': 136,\n",
       " 'gracenote-E3_sixteenth': 137,\n",
       " 'gracenote-E#4_eighth': 138,\n",
       " 'gracenote-E4_eighth': 139,\n",
       " 'gracenote-E4_quarter': 140,\n",
       " 'gracenote-E#4_sixteenth': 141,\n",
       " 'gracenote-E4_sixteenth': 142,\n",
       " 'gracenote-E4_thirty_second': 143,\n",
       " 'gracenote-E#5_eighth': 144,\n",
       " 'gracenote-E5_eighth': 145,\n",
       " 'gracenote-E5_half': 146,\n",
       " 'gracenote-E#5_quarter': 147,\n",
       " 'gracenote-E5_quarter': 148,\n",
       " 'gracenote-E#5_sixteenth': 149,\n",
       " 'gracenote-E5_sixteenth': 150,\n",
       " 'gracenote-E5_thirty_second': 151,\n",
       " 'gracenote-Eb3_eighth': 152,\n",
       " 'gracenote-Eb3_quarter': 153,\n",
       " 'gracenote-Eb3_sixteenth': 154,\n",
       " 'gracenote-Eb4_eighth': 155,\n",
       " 'gracenote-Eb4_quarter': 156,\n",
       " 'gracenote-Eb4_sixteenth': 157,\n",
       " 'gracenote-Eb4_thirty_second': 158,\n",
       " 'gracenote-Eb5_eighth': 159,\n",
       " 'gracenote-Eb5_quarter': 160,\n",
       " 'gracenote-Eb5_quarter.': 161,\n",
       " 'gracenote-Eb5_sixteenth': 162,\n",
       " 'gracenote-Eb5_thirty_second': 163,\n",
       " 'gracenote-F2_eighth': 164,\n",
       " 'gracenote-F#2_quarter': 165,\n",
       " 'gracenote-F#3_eighth': 166,\n",
       " 'gracenote-F3_eighth': 167,\n",
       " 'gracenote-F#3_quarter': 168,\n",
       " 'gracenote-F3_quarter': 169,\n",
       " 'gracenote-F#3_sixteenth': 170,\n",
       " 'gracenote-F3_sixteenth': 171,\n",
       " 'gracenote-F3_thirty_second': 172,\n",
       " 'gracenote-F#4_eighth': 173,\n",
       " 'gracenote-F4_eighth': 174,\n",
       " 'gracenote-F#4_quarter': 175,\n",
       " 'gracenote-F4_quarter': 176,\n",
       " 'gracenote-F#4_sixteenth': 177,\n",
       " 'gracenote-F4_sixteenth': 178,\n",
       " 'gracenote-F#4_thirty_second': 179,\n",
       " 'gracenote-F4_thirty_second': 180,\n",
       " 'gracenote-F#5_eighth': 181,\n",
       " 'gracenote-F5_eighth': 182,\n",
       " 'gracenote-F5_half': 183,\n",
       " 'gracenote-F#5_quarter': 184,\n",
       " 'gracenote-F5_quarter': 185,\n",
       " 'gracenote-F#5_sixteenth': 186,\n",
       " 'gracenote-F5_sixteenth': 187,\n",
       " 'gracenote-F5_sixteenth.': 188,\n",
       " 'gracenote-F#5_thirty_second': 189,\n",
       " 'gracenote-F5_thirty_second': 190,\n",
       " 'gracenote-G#3_eighth': 191,\n",
       " 'gracenote-G3_eighth': 192,\n",
       " 'gracenote-G3_quarter': 193,\n",
       " 'gracenote-G#3_sixteenth': 194,\n",
       " 'gracenote-G3_sixteenth': 195,\n",
       " 'gracenote-G#3_thirty_second': 196,\n",
       " 'gracenote-G3_thirty_second': 197,\n",
       " 'gracenote-G#4_eighth': 198,\n",
       " 'gracenote-G4_eighth': 199,\n",
       " 'gracenote-G4_eighth.': 200,\n",
       " 'gracenote-G4_half': 201,\n",
       " 'gracenote-G#4_quarter': 202,\n",
       " 'gracenote-G4_quarter': 203,\n",
       " 'gracenote-G#4_sixteenth': 204,\n",
       " 'gracenote-G4_sixteenth': 205,\n",
       " 'gracenote-G#4_thirty_second': 206,\n",
       " 'gracenote-G4_thirty_second': 207,\n",
       " 'gracenote-G#5_eighth': 208,\n",
       " 'gracenote-G5_eighth': 209,\n",
       " 'gracenote-G5_half': 210,\n",
       " 'gracenote-G#5_quarter': 211,\n",
       " 'gracenote-G5_quarter': 212,\n",
       " 'gracenote-G#5_sixteenth': 213,\n",
       " 'gracenote-G5_sixteenth': 214,\n",
       " 'gracenote-G5_sixteenth.': 215,\n",
       " 'gracenote-G#5_thirty_second': 216,\n",
       " 'gracenote-G5_thirty_second': 217,\n",
       " 'gracenote-Gb4_eighth': 218,\n",
       " 'gracenote-Gb4_quarter': 219,\n",
       " 'gracenote-Gb5_thirty_second': 220,\n",
       " 'keySignature-AbM': 221,\n",
       " 'keySignature-AM': 222,\n",
       " 'keySignature-BbM': 223,\n",
       " 'keySignature-BM': 224,\n",
       " 'keySignature-CM': 225,\n",
       " 'keySignature-C#M': 226,\n",
       " 'keySignature-DbM': 227,\n",
       " 'keySignature-DM': 228,\n",
       " 'keySignature-EbM': 229,\n",
       " 'keySignature-EM': 230,\n",
       " 'keySignature-FM': 231,\n",
       " 'keySignature-F#M': 232,\n",
       " 'keySignature-GbM': 233,\n",
       " 'keySignature-GM': 234,\n",
       " 'multirest-1': 235,\n",
       " 'multirest-10': 236,\n",
       " 'multirest-100': 237,\n",
       " 'multirest-105': 238,\n",
       " 'multirest-107': 239,\n",
       " 'multirest-11': 240,\n",
       " 'multirest-1111': 241,\n",
       " 'multirest-112': 242,\n",
       " 'multirest-115': 243,\n",
       " 'multirest-119': 244,\n",
       " 'multirest-12': 245,\n",
       " 'multirest-123': 246,\n",
       " 'multirest-124': 247,\n",
       " 'multirest-126': 248,\n",
       " 'multirest-128': 249,\n",
       " 'multirest-13': 250,\n",
       " 'multirest-14': 251,\n",
       " 'multirest-143': 252,\n",
       " 'multirest-15': 253,\n",
       " 'multirest-16': 254,\n",
       " 'multirest-164': 255,\n",
       " 'multirest-17': 256,\n",
       " 'multirest-18': 257,\n",
       " 'multirest-19': 258,\n",
       " 'multirest-193': 259,\n",
       " 'multirest-2': 260,\n",
       " 'multirest-20': 261,\n",
       " 'multirest-21': 262,\n",
       " 'multirest-22': 263,\n",
       " 'multirest-225': 264,\n",
       " 'multirest-23': 265,\n",
       " 'multirest-24': 266,\n",
       " 'multirest-25': 267,\n",
       " 'multirest-26': 268,\n",
       " 'multirest-27': 269,\n",
       " 'multirest-28': 270,\n",
       " 'multirest-29': 271,\n",
       " 'multirest-3': 272,\n",
       " 'multirest-30': 273,\n",
       " 'multirest-31': 274,\n",
       " 'multirest-32': 275,\n",
       " 'multirest-33': 276,\n",
       " 'multirest-34': 277,\n",
       " 'multirest-35': 278,\n",
       " 'multirest-36': 279,\n",
       " 'multirest-37': 280,\n",
       " 'multirest-38': 281,\n",
       " 'multirest-39': 282,\n",
       " 'multirest-4': 283,\n",
       " 'multirest-40': 284,\n",
       " 'multirest-41': 285,\n",
       " 'multirest-42': 286,\n",
       " 'multirest-43': 287,\n",
       " 'multirest-44': 288,\n",
       " 'multirest-45': 289,\n",
       " 'multirest-46': 290,\n",
       " 'multirest-47': 291,\n",
       " 'multirest-48': 292,\n",
       " 'multirest-49': 293,\n",
       " 'multirest-5': 294,\n",
       " 'multirest-50': 295,\n",
       " 'multirest-51': 296,\n",
       " 'multirest-52': 297,\n",
       " 'multirest-53': 298,\n",
       " 'multirest-54': 299,\n",
       " 'multirest-55': 300,\n",
       " 'multirest-56': 301,\n",
       " 'multirest-57': 302,\n",
       " 'multirest-58': 303,\n",
       " 'multirest-59': 304,\n",
       " 'multirest-6': 305,\n",
       " 'multirest-60': 306,\n",
       " 'multirest-63': 307,\n",
       " 'multirest-64': 308,\n",
       " 'multirest-65': 309,\n",
       " 'multirest-66': 310,\n",
       " 'multirest-67': 311,\n",
       " 'multirest-68': 312,\n",
       " 'multirest-69': 313,\n",
       " 'multirest-7': 314,\n",
       " 'multirest-70': 315,\n",
       " 'multirest-71': 316,\n",
       " 'multirest-72': 317,\n",
       " 'multirest-73': 318,\n",
       " 'multirest-76': 319,\n",
       " 'multirest-77': 320,\n",
       " 'multirest-79': 321,\n",
       " 'multirest-8': 322,\n",
       " 'multirest-80': 323,\n",
       " 'multirest-81': 324,\n",
       " 'multirest-88': 325,\n",
       " 'multirest-89': 326,\n",
       " 'multirest-9': 327,\n",
       " 'multirest-91': 328,\n",
       " 'multirest-94': 329,\n",
       " 'multirest-96': 330,\n",
       " 'multirest-98': 331,\n",
       " 'multirest-99': 332,\n",
       " 'note-A1_sixteenth': 333,\n",
       " 'note-A2_double_whole': 334,\n",
       " 'note-A2_double_whole.': 335,\n",
       " 'note-A2_double_whole_fermata': 336,\n",
       " 'note-A#2_eighth': 337,\n",
       " 'note-A2_eighth': 338,\n",
       " 'note-A2_eighth.': 339,\n",
       " 'note-A#2_half': 340,\n",
       " 'note-A2_half': 341,\n",
       " 'note-A2_half.': 342,\n",
       " 'note-A2_half_fermata': 343,\n",
       " 'note-A2_quadruple_whole': 344,\n",
       " 'note-A2_quadruple_whole_fermata': 345,\n",
       " 'note-A#2_quarter': 346,\n",
       " 'note-A#2_quarter.': 347,\n",
       " 'note-A2_quarter': 348,\n",
       " 'note-A2_quarter.': 349,\n",
       " 'note-A2_quarter_fermata': 350,\n",
       " 'note-A#2_sixteenth': 351,\n",
       " 'note-A#2_sixteenth.': 352,\n",
       " 'note-A2_sixteenth': 353,\n",
       " 'note-A2_sixteenth.': 354,\n",
       " 'note-A2_sixty_fourth': 355,\n",
       " 'note-A2_thirty_second': 356,\n",
       " 'note-A#2_whole': 357,\n",
       " 'note-A2_whole': 358,\n",
       " 'note-A2_whole.': 359,\n",
       " 'note-A2_whole_fermata': 360,\n",
       " 'note-A3_double_whole': 361,\n",
       " 'note-A3_double_whole.': 362,\n",
       " 'note-A3_double_whole_fermata': 363,\n",
       " 'note-A#3_eighth': 364,\n",
       " 'note-A#3_eighth.': 365,\n",
       " 'note-A3_eighth': 366,\n",
       " 'note-A3_eighth.': 367,\n",
       " 'note-A3_eighth..': 368,\n",
       " 'note-A3_eighth_fermata': 369,\n",
       " 'note-A3_eighth._fermata': 370,\n",
       " 'note-A#3_half': 371,\n",
       " 'note-A#3_half.': 372,\n",
       " 'note-A3_half': 373,\n",
       " 'note-A3_half.': 374,\n",
       " 'note-A#3_half_fermata': 375,\n",
       " 'note-A3_half_fermata': 376,\n",
       " 'note-A3_half._fermata': 377,\n",
       " 'note-A3_quadruple_whole': 378,\n",
       " 'note-A#3_quarter': 379,\n",
       " 'note-A#3_quarter.': 380,\n",
       " 'note-A3_quarter': 381,\n",
       " 'note-A3_quarter.': 382,\n",
       " 'note-A3_quarter..': 383,\n",
       " 'note-A3_quarter_fermata': 384,\n",
       " 'note-A#3_sixteenth': 385,\n",
       " 'note-A#3_sixteenth.': 386,\n",
       " 'note-A3_sixteenth': 387,\n",
       " 'note-A3_sixteenth.': 388,\n",
       " 'note-A#3_sixty_fourth': 389,\n",
       " 'note-A3_sixty_fourth': 390,\n",
       " 'note-A#3_thirty_second': 391,\n",
       " 'note-A3_thirty_second': 392,\n",
       " 'note-A#3_whole': 393,\n",
       " 'note-A3_whole': 394,\n",
       " 'note-A3_whole.': 395,\n",
       " 'note-A3_whole_fermata': 396,\n",
       " 'note-A4_double_whole': 397,\n",
       " 'note-A4_double_whole.': 398,\n",
       " 'note-A4_double_whole_fermata': 399,\n",
       " 'note-A#4_eighth': 400,\n",
       " 'note-A#4_eighth.': 401,\n",
       " 'note-A4_eighth': 402,\n",
       " 'note-A4_eighth.': 403,\n",
       " 'note-A4_eighth..': 404,\n",
       " 'note-A4_eighth_fermata': 405,\n",
       " 'note-A#4_half': 406,\n",
       " 'note-A#4_half.': 407,\n",
       " 'note-A4_half': 408,\n",
       " 'note-A4_half.': 409,\n",
       " 'note-A4_half..': 410,\n",
       " 'note-A#4_half_fermata': 411,\n",
       " 'note-A4_half_fermata': 412,\n",
       " 'note-A4_half._fermata': 413,\n",
       " 'note-A4_quadruple_whole': 414,\n",
       " 'note-A4_quadruple_whole.': 415,\n",
       " 'note-A#4_quarter': 416,\n",
       " 'note-A#4_quarter.': 417,\n",
       " 'note-A4_quarter': 418,\n",
       " 'note-A4_quarter.': 419,\n",
       " 'note-A4_quarter..': 420,\n",
       " 'note-A#4_quarter_fermata': 421,\n",
       " 'note-A4_quarter_fermata': 422,\n",
       " 'note-A4_quarter._fermata': 423,\n",
       " 'note-A#4_sixteenth': 424,\n",
       " 'note-A#4_sixteenth.': 425,\n",
       " 'note-A4_sixteenth': 426,\n",
       " 'note-A4_sixteenth.': 427,\n",
       " 'note-A4_sixty_fourth': 428,\n",
       " 'note-A#4_thirty_second': 429,\n",
       " 'note-A4_thirty_second': 430,\n",
       " 'note-A4_thirty_second.': 431,\n",
       " 'note-A#4_whole': 432,\n",
       " 'note-A#4_whole.': 433,\n",
       " 'note-A4_whole': 434,\n",
       " 'note-A4_whole.': 435,\n",
       " 'note-A4_whole_fermata': 436,\n",
       " 'note-A4_whole._fermata': 437,\n",
       " 'note-A5_double_whole': 438,\n",
       " 'note-A#5_eighth': 439,\n",
       " 'note-A#5_eighth.': 440,\n",
       " 'note-A5_eighth': 441,\n",
       " 'note-A5_eighth.': 442,\n",
       " 'note-A5_eighth..': 443,\n",
       " 'note-A5_eighth_fermata': 444,\n",
       " 'note-A#5_half': 445,\n",
       " 'note-A#5_half.': 446,\n",
       " 'note-A5_half': 447,\n",
       " 'note-A5_half.': 448,\n",
       " 'note-A5_half_fermata': 449,\n",
       " 'note-A5_half._fermata': 450,\n",
       " 'note-A#5_quarter': 451,\n",
       " 'note-A#5_quarter.': 452,\n",
       " 'note-A5_quarter': 453,\n",
       " 'note-A5_quarter.': 454,\n",
       " 'note-A5_quarter..': 455,\n",
       " 'note-A5_quarter_fermata': 456,\n",
       " 'note-A5_quarter._fermata': 457,\n",
       " 'note-A#5_sixteenth': 458,\n",
       " 'note-A#5_sixteenth.': 459,\n",
       " 'note-A5_sixteenth': 460,\n",
       " 'note-A5_sixteenth.': 461,\n",
       " 'note-A5_sixty_fourth': 462,\n",
       " 'note-A#5_thirty_second': 463,\n",
       " 'note-A5_thirty_second': 464,\n",
       " 'note-A5_thirty_second.': 465,\n",
       " 'note-A5_whole': 466,\n",
       " 'note-A5_whole.': 467,\n",
       " 'note-A5_whole_fermata': 468,\n",
       " 'note-Ab2_eighth': 469,\n",
       " 'note-Ab2_eighth.': 470,\n",
       " 'note-Ab2_half': 471,\n",
       " 'note-Ab2_half.': 472,\n",
       " 'note-Ab2_half_fermata': 473,\n",
       " 'note-Ab2_quarter': 474,\n",
       " 'note-Ab2_quarter.': 475,\n",
       " 'note-Ab2_sixteenth': 476,\n",
       " 'note-Ab2_thirty_second': 477,\n",
       " 'note-Ab2_whole': 478,\n",
       " 'note-Ab3_eighth': 479,\n",
       " 'note-Ab3_eighth.': 480,\n",
       " 'note-Ab3_half': 481,\n",
       " 'note-Ab3_half.': 482,\n",
       " 'note-Ab3_quarter': 483,\n",
       " 'note-Ab3_quarter.': 484,\n",
       " 'note-Ab3_quarter..': 485,\n",
       " 'note-Ab3_sixteenth': 486,\n",
       " 'note-Ab3_sixteenth.': 487,\n",
       " 'note-Ab3_thirty_second': 488,\n",
       " 'note-Ab3_whole': 489,\n",
       " 'note-Ab4_eighth': 490,\n",
       " 'note-Ab4_eighth.': 491,\n",
       " 'note-Ab4_eighth..': 492,\n",
       " 'note-Ab4_half': 493,\n",
       " 'note-Ab4_half.': 494,\n",
       " 'note-Ab4_half_fermata': 495,\n",
       " 'note-Ab4_half._fermata': 496,\n",
       " 'note-Ab4_quarter': 497,\n",
       " 'note-Ab4_quarter.': 498,\n",
       " 'note-Ab4_quarter..': 499,\n",
       " 'note-Ab4_quarter_fermata': 500,\n",
       " 'note-Ab4_sixteenth': 501,\n",
       " 'note-Ab4_sixteenth.': 502,\n",
       " 'note-Ab4_sixty_fourth': 503,\n",
       " 'note-Ab4_thirty_second': 504,\n",
       " 'note-Ab4_thirty_second.': 505,\n",
       " 'note-Ab4_whole': 506,\n",
       " 'note-Ab4_whole.': 507,\n",
       " 'note-Ab4_whole_fermata': 508,\n",
       " 'note-Ab5_eighth': 509,\n",
       " 'note-Ab5_eighth.': 510,\n",
       " 'note-Ab5_eighth..': 511,\n",
       " 'note-Ab5_half': 512,\n",
       " 'note-Ab5_half.': 513,\n",
       " 'note-Ab5_half._fermata': 514,\n",
       " 'note-Ab5_quarter': 515,\n",
       " 'note-Ab5_quarter.': 516,\n",
       " 'note-Ab5_quarter_fermata': 517,\n",
       " 'note-Ab5_sixteenth': 518,\n",
       " 'note-Ab5_sixteenth.': 519,\n",
       " 'note-Ab5_sixty_fourth': 520,\n",
       " 'note-Ab5_thirty_second': 521,\n",
       " 'note-Ab5_whole': 522,\n",
       " 'note-B1_quarter': 523,\n",
       " 'note-B2_double_whole': 524,\n",
       " 'note-B#2_eighth': 525,\n",
       " 'note-B#2_eighth.': 526,\n",
       " 'note-B2_eighth': 527,\n",
       " 'note-B2_eighth.': 528,\n",
       " 'note-B#2_half': 529,\n",
       " 'note-B2_half': 530,\n",
       " 'note-B2_half.': 531,\n",
       " 'note-B2_half_fermata': 532,\n",
       " 'note-B#2_quarter': 533,\n",
       " 'note-B2_quarter': 534,\n",
       " 'note-B2_quarter.': 535,\n",
       " 'note-B#2_sixteenth': 536,\n",
       " 'note-B2_sixteenth': 537,\n",
       " 'note-B2_sixteenth.': 538,\n",
       " 'note-B2_sixty_fourth': 539,\n",
       " 'note-B2_thirty_second': 540,\n",
       " 'note-B#2_whole': 541,\n",
       " 'note-B2_whole': 542,\n",
       " 'note-B2_whole.': 543,\n",
       " 'note-B#3_double_whole': 544,\n",
       " 'note-B#3_double_whole.': 545,\n",
       " 'note-B3_double_whole': 546,\n",
       " 'note-B3_double_whole.': 547,\n",
       " 'note-B3_double_whole_fermata': 548,\n",
       " 'note-B#3_eighth': 549,\n",
       " 'note-B#3_eighth.': 550,\n",
       " 'note-B3_eighth': 551,\n",
       " 'note-B3_eighth.': 552,\n",
       " 'note-B3_eighth_fermata': 553,\n",
       " 'note-B#3_half': 554,\n",
       " 'note-B#3_half.': 555,\n",
       " 'note-B3_half': 556,\n",
       " 'note-B3_half.': 557,\n",
       " 'note-B3_half_fermata': 558,\n",
       " 'note-B#3_quarter': 559,\n",
       " 'note-B#3_quarter.': 560,\n",
       " 'note-B3_quarter': 561,\n",
       " 'note-B3_quarter.': 562,\n",
       " 'note-B3_quarter..': 563,\n",
       " 'note-B3_quarter_fermata': 564,\n",
       " 'note-B#3_sixteenth': 565,\n",
       " 'note-B3_sixteenth': 566,\n",
       " 'note-B3_sixteenth.': 567,\n",
       " 'note-B3_sixty_fourth': 568,\n",
       " 'note-B#3_thirty_second': 569,\n",
       " 'note-B3_thirty_second': 570,\n",
       " 'note-B3_thirty_second.': 571,\n",
       " 'note-B#3_whole': 572,\n",
       " 'note-B3_whole': 573,\n",
       " 'note-B3_whole.': 574,\n",
       " 'note-B3_whole_fermata': 575,\n",
       " 'note-B#4_double_whole': 576,\n",
       " 'note-B4_double_whole': 577,\n",
       " 'note-B4_double_whole.': 578,\n",
       " 'note-B#4_double_whole_fermata': 579,\n",
       " 'note-B4_double_whole_fermata': 580,\n",
       " 'note-B#4_eighth': 581,\n",
       " 'note-B#4_eighth.': 582,\n",
       " 'note-B4_eighth': 583,\n",
       " 'note-B4_eighth.': 584,\n",
       " 'note-B4_eighth..': 585,\n",
       " 'note-B4_eighth_fermata': 586,\n",
       " 'note-B4_eighth._fermata': 587,\n",
       " 'note-B#4_half': 588,\n",
       " 'note-B#4_half.': 589,\n",
       " 'note-B4_half': 590,\n",
       " 'note-B4_half.': 591,\n",
       " 'note-B4_half_fermata': 592,\n",
       " 'note-B4_half._fermata': 593,\n",
       " 'note-B4_quadruple_whole': 594,\n",
       " 'note-B#4_quarter': 595,\n",
       " 'note-B#4_quarter.': 596,\n",
       " 'note-B4_quarter': 597,\n",
       " 'note-B4_quarter.': 598,\n",
       " 'note-B4_quarter..': 599,\n",
       " 'note-B4_quarter_fermata': 600,\n",
       " 'note-B4_quarter._fermata': 601,\n",
       " 'note-B#4_sixteenth': 602,\n",
       " 'note-B#4_sixteenth.': 603,\n",
       " 'note-B4_sixteenth': 604,\n",
       " 'note-B4_sixteenth.': 605,\n",
       " 'note-B4_sixteenth_fermata': 606,\n",
       " 'note-B4_sixteenth._fermata': 607,\n",
       " 'note-B4_sixty_fourth': 608,\n",
       " 'note-B#4_thirty_second': 609,\n",
       " 'note-B4_thirty_second': 610,\n",
       " 'note-B4_thirty_second.': 611,\n",
       " 'note-B#4_whole': 612,\n",
       " 'note-B#4_whole.': 613,\n",
       " 'note-B4_whole': 614,\n",
       " 'note-B4_whole.': 615,\n",
       " 'note-B4_whole_fermata': 616,\n",
       " 'note-B4_whole._fermata': 617,\n",
       " 'note-B5_double_whole': 618,\n",
       " 'note-B#5_eighth': 619,\n",
       " 'note-B5_eighth': 620,\n",
       " 'note-B5_eighth.': 621,\n",
       " 'note-B5_eighth..': 622,\n",
       " 'note-B5_half': 623,\n",
       " 'note-B5_half.': 624,\n",
       " 'note-B5_half_fermata': 625,\n",
       " 'note-B#5_quarter': 626,\n",
       " 'note-B5_quarter': 627,\n",
       " 'note-B5_quarter.': 628,\n",
       " 'note-B5_quarter..': 629,\n",
       " 'note-B#5_sixteenth': 630,\n",
       " 'note-B5_sixteenth': 631,\n",
       " 'note-B5_sixteenth.': 632,\n",
       " 'note-B5_sixty_fourth': 633,\n",
       " 'note-B5_thirty_second': 634,\n",
       " 'note-B5_whole': 635,\n",
       " 'note-B5_whole.': 636,\n",
       " 'note-Bb1_half': 637,\n",
       " 'note-Bb2_double_whole': 638,\n",
       " 'note-Bb2_eighth': 639,\n",
       " 'note-Bb2_eighth.': 640,\n",
       " 'note-Bb2_half': 641,\n",
       " 'note-Bb2_half.': 642,\n",
       " 'note-Bb2_quarter': 643,\n",
       " 'note-Bb2_quarter.': 644,\n",
       " 'note-Bb2_quarter_fermata': 645,\n",
       " 'note-Bb2_quarter._fermata': 646,\n",
       " 'note-Bb2_sixteenth': 647,\n",
       " 'note-Bb2_sixteenth.': 648,\n",
       " 'note-Bb2_sixteenth_fermata': 649,\n",
       " 'note-Bb2_thirty_second': 650,\n",
       " 'note-Bb2_whole': 651,\n",
       " 'note-Bb2_whole.': 652,\n",
       " 'note-Bb3_double_whole': 653,\n",
       " 'note-Bb3_double_whole.': 654,\n",
       " 'note-Bb3_eighth': 655,\n",
       " 'note-Bb3_eighth.': 656,\n",
       " 'note-Bb3_eighth..': 657,\n",
       " 'note-Bb3_half': 658,\n",
       " 'note-Bb3_half.': 659,\n",
       " 'note-Bb3_half_fermata': 660,\n",
       " 'note-Bb3_half._fermata': 661,\n",
       " 'note-Bb3_quadruple_whole': 662,\n",
       " 'note-Bb3_quarter': 663,\n",
       " 'note-Bb3_quarter.': 664,\n",
       " 'note-Bb3_quarter..': 665,\n",
       " 'note-Bb3_quarter_fermata': 666,\n",
       " 'note-Bb3_quarter._fermata': 667,\n",
       " 'note-Bb3_sixteenth': 668,\n",
       " 'note-Bb3_sixteenth.': 669,\n",
       " 'note-Bb3_sixty_fourth': 670,\n",
       " 'note-Bb3_thirty_second': 671,\n",
       " 'note-Bb3_thirty_second.': 672,\n",
       " 'note-Bb3_whole': 673,\n",
       " 'note-Bb3_whole.': 674,\n",
       " 'note-Bb3_whole_fermata': 675,\n",
       " 'note-Bb4_double_whole': 676,\n",
       " 'note-Bb4_double_whole.': 677,\n",
       " 'note-Bb4_eighth': 678,\n",
       " 'note-Bb4_eighth.': 679,\n",
       " 'note-Bb4_eighth..': 680,\n",
       " 'note-Bb4_eighth_fermata': 681,\n",
       " 'note-Bb4_half': 682,\n",
       " 'note-Bb4_half.': 683,\n",
       " 'note-Bb4_half_fermata': 684,\n",
       " 'note-Bb4_half._fermata': 685,\n",
       " 'note-Bb4_quadruple_whole': 686,\n",
       " 'note-Bb4_quarter': 687,\n",
       " 'note-Bb4_quarter.': 688,\n",
       " 'note-Bb4_quarter..': 689,\n",
       " 'note-Bb4_quarter_fermata': 690,\n",
       " 'note-Bb4_quarter._fermata': 691,\n",
       " 'note-Bb4_sixteenth': 692,\n",
       " 'note-Bb4_sixteenth.': 693,\n",
       " 'note-Bb4_sixty_fourth': 694,\n",
       " 'note-Bb4_thirty_second': 695,\n",
       " 'note-Bb4_thirty_second.': 696,\n",
       " 'note-Bb4_whole': 697,\n",
       " 'note-Bb4_whole.': 698,\n",
       " 'note-Bb4_whole_fermata': 699,\n",
       " 'note-Bb4_whole._fermata': 700,\n",
       " 'note-Bb5_double_whole': 701,\n",
       " 'note-Bb5_eighth': 702,\n",
       " 'note-Bb5_eighth.': 703,\n",
       " 'note-Bb5_eighth..': 704,\n",
       " 'note-Bb5_half': 705,\n",
       " 'note-Bb5_half.': 706,\n",
       " 'note-Bb5_half_fermata': 707,\n",
       " 'note-Bb5_quarter': 708,\n",
       " 'note-Bb5_quarter.': 709,\n",
       " 'note-Bb5_quarter..': 710,\n",
       " 'note-Bb5_quarter_fermata': 711,\n",
       " 'note-Bb5_sixteenth': 712,\n",
       " 'note-Bb5_sixteenth.': 713,\n",
       " 'note-Bb5_sixty_fourth': 714,\n",
       " 'note-Bb5_thirty_second': 715,\n",
       " 'note-Bb5_thirty_second.': 716,\n",
       " 'note-Bb5_whole': 717,\n",
       " 'note-Bb5_whole.': 718,\n",
       " 'note-Bb5_whole_fermata': 719,\n",
       " 'note-C2_double_whole.': 720,\n",
       " 'note-C#2_eighth': 721,\n",
       " 'note-C#2_eighth.': 722,\n",
       " 'note-C2_eighth': 723,\n",
       " 'note-C2_eighth.': 724,\n",
       " 'note-C2_half': 725,\n",
       " 'note-C2_half.': 726,\n",
       " 'note-C2_half_fermata': 727,\n",
       " 'note-C#2_quarter': 728,\n",
       " 'note-C#2_quarter.': 729,\n",
       " 'note-C2_quarter': 730,\n",
       " 'note-C2_quarter.': 731,\n",
       " 'note-C#2_sixteenth': 732,\n",
       " 'note-C2_sixteenth': 733,\n",
       " 'note-C2_thirty_second': 734,\n",
       " 'note-C#2_whole': 735,\n",
       " 'note-C2_whole': 736,\n",
       " 'note-C#3_double_whole': 737,\n",
       " 'note-C3_double_whole': 738,\n",
       " 'note-C3_double_whole.': 739,\n",
       " 'note-C3_double_whole_fermata': 740,\n",
       " 'note-C#3_eighth': 741,\n",
       " 'note-C#3_eighth.': 742,\n",
       " 'note-C3_eighth': 743,\n",
       " 'note-C3_eighth.': 744,\n",
       " 'note-C#3_half': 745,\n",
       " 'note-C#3_half.': 746,\n",
       " 'note-C3_half': 747,\n",
       " 'note-C3_half.': 748,\n",
       " 'note-C3_half_fermata': 749,\n",
       " 'note-C3_quadruple_whole': 750,\n",
       " 'note-C3_quadruple_whole.': 751,\n",
       " 'note-C#3_quarter': 752,\n",
       " 'note-C#3_quarter.': 753,\n",
       " 'note-C3_quarter': 754,\n",
       " 'note-C3_quarter.': 755,\n",
       " 'note-C3_quarter_fermata': 756,\n",
       " 'note-C#3_sixteenth': 757,\n",
       " 'note-C#3_sixteenth.': 758,\n",
       " 'note-C3_sixteenth': 759,\n",
       " 'note-C3_sixteenth.': 760,\n",
       " 'note-C3_sixty_fourth': 761,\n",
       " 'note-C#3_thirty_second': 762,\n",
       " 'note-C3_thirty_second': 763,\n",
       " 'note-C#3_whole': 764,\n",
       " 'note-C3_whole': 765,\n",
       " 'note-C3_whole.': 766,\n",
       " 'note-C3_whole_fermata': 767,\n",
       " 'note-C4_double_whole': 768,\n",
       " 'note-C4_double_whole.': 769,\n",
       " 'note-C4_double_whole_fermata': 770,\n",
       " 'note-C#4_eighth': 771,\n",
       " 'note-C#4_eighth.': 772,\n",
       " 'note-C#4_eighth..': 773,\n",
       " 'note-C4_eighth': 774,\n",
       " 'note-C4_eighth.': 775,\n",
       " 'note-C4_eighth..': 776,\n",
       " 'note-C#4_eighth_fermata': 777,\n",
       " 'note-C4_eighth_fermata': 778,\n",
       " 'note-C#4_half': 779,\n",
       " 'note-C#4_half.': 780,\n",
       " 'note-C4_half': 781,\n",
       " 'note-C4_half.': 782,\n",
       " 'note-C#4_half_fermata': 783,\n",
       " 'note-C4_half_fermata': 784,\n",
       " 'note-C4_half._fermata': 785,\n",
       " 'note-C4_hundred_twenty_eighth': 786,\n",
       " 'note-C4_quadruple_whole': 787,\n",
       " 'note-C4_quadruple_whole.': 788,\n",
       " 'note-C#4_quadruple_whole_fermata': 789,\n",
       " 'note-C#4_quarter': 790,\n",
       " 'note-C#4_quarter.': 791,\n",
       " 'note-C#4_quarter..': 792,\n",
       " 'note-C4_quarter': 793,\n",
       " 'note-C4_quarter.': 794,\n",
       " 'note-C4_quarter..': 795,\n",
       " 'note-C#4_quarter_fermata': 796,\n",
       " 'note-C#4_quarter._fermata': 797,\n",
       " 'note-C4_quarter_fermata': 798,\n",
       " 'note-C4_quarter._fermata': 799,\n",
       " 'note-C#4_sixteenth': 800,\n",
       " 'note-C#4_sixteenth.': 801,\n",
       " 'note-C4_sixteenth': 802,\n",
       " 'note-C4_sixteenth.': 803,\n",
       " 'note-C#4_sixty_fourth': 804,\n",
       " 'note-C4_sixty_fourth': 805,\n",
       " 'note-C#4_thirty_second': 806,\n",
       " 'note-C4_thirty_second': 807,\n",
       " 'note-C4_thirty_second.': 808,\n",
       " 'note-C#4_whole': 809,\n",
       " 'note-C#4_whole.': 810,\n",
       " 'note-C4_whole': 811,\n",
       " 'note-C4_whole.': 812,\n",
       " 'note-C#4_whole_fermata': 813,\n",
       " 'note-C4_whole_fermata': 814,\n",
       " 'note-C#5_double_whole': 815,\n",
       " 'note-C5_double_whole': 816,\n",
       " 'note-C5_double_whole.': 817,\n",
       " 'note-C5_double_whole_fermata': 818,\n",
       " 'note-C5_double_whole._fermata': 819,\n",
       " 'note-C#5_eighth': 820,\n",
       " 'note-C#5_eighth.': 821,\n",
       " 'note-C#5_eighth..': 822,\n",
       " 'note-C5_eighth': 823,\n",
       " 'note-C5_eighth.': 824,\n",
       " 'note-C5_eighth..': 825,\n",
       " 'note-C#5_eighth_fermata': 826,\n",
       " 'note-C#5_eighth._fermata': 827,\n",
       " 'note-C5_eighth_fermata': 828,\n",
       " 'note-C5_eighth._fermata': 829,\n",
       " 'note-C#5_half': 830,\n",
       " 'note-C#5_half.': 831,\n",
       " 'note-C5_half': 832,\n",
       " 'note-C5_half.': 833,\n",
       " 'note-C#5_half_fermata': 834,\n",
       " 'note-C#5_half._fermata': 835,\n",
       " 'note-C5_half_fermata': 836,\n",
       " 'note-C5_half._fermata': 837,\n",
       " 'note-C5_quadruple_whole': 838,\n",
       " 'note-C5_quadruple_whole.': 839,\n",
       " 'note-C5_quadruple_whole_fermata': 840,\n",
       " 'note-C#5_quarter': 841,\n",
       " 'note-C#5_quarter.': 842,\n",
       " 'note-C#5_quarter..': 843,\n",
       " 'note-C5_quarter': 844,\n",
       " 'note-C5_quarter.': 845,\n",
       " 'note-C5_quarter..': 846,\n",
       " 'note-C#5_quarter_fermata': 847,\n",
       " 'note-C#5_quarter._fermata': 848,\n",
       " 'note-C5_quarter_fermata': 849,\n",
       " 'note-C5_quarter._fermata': 850,\n",
       " 'note-C#5_sixteenth': 851,\n",
       " 'note-C#5_sixteenth.': 852,\n",
       " 'note-C5_sixteenth': 853,\n",
       " 'note-C5_sixteenth.': 854,\n",
       " 'note-C#5_sixteenth._fermata': 855,\n",
       " 'note-C5_sixteenth_fermata': 856,\n",
       " 'note-C#5_sixty_fourth': 857,\n",
       " 'note-C#5_sixty_fourth.': 858,\n",
       " 'note-C5_sixty_fourth': 859,\n",
       " 'note-C#5_thirty_second': 860,\n",
       " 'note-C5_thirty_second': 861,\n",
       " 'note-C5_thirty_second.': 862,\n",
       " 'note-C#5_whole': 863,\n",
       " 'note-C#5_whole.': 864,\n",
       " 'note-C5_whole': 865,\n",
       " 'note-C5_whole.': 866,\n",
       " 'note-C#5_whole_fermata': 867,\n",
       " 'note-C5_whole_fermata': 868,\n",
       " 'note-C5_whole._fermata': 869,\n",
       " 'note-C#6_eighth': 870,\n",
       " 'note-C#6_eighth.': 871,\n",
       " 'note-C6_eighth': 872,\n",
       " 'note-C6_eighth.': 873,\n",
       " 'note-C6_eighth..': 874,\n",
       " 'note-C#6_half': 875,\n",
       " 'note-C#6_half.': 876,\n",
       " 'note-C6_half': 877,\n",
       " 'note-C6_half.': 878,\n",
       " 'note-C6_half..': 879,\n",
       " 'note-C#6_half_fermata': 880,\n",
       " 'note-C6_half_fermata': 881,\n",
       " 'note-C6_half._fermata': 882,\n",
       " 'note-C#6_quarter': 883,\n",
       " 'note-C#6_quarter.': 884,\n",
       " 'note-C#6_quarter..': 885,\n",
       " 'note-C6_quarter': 886,\n",
       " 'note-C6_quarter.': 887,\n",
       " 'note-C6_quarter..': 888,\n",
       " 'note-C#6_sixteenth': 889,\n",
       " 'note-C#6_sixteenth.': 890,\n",
       " 'note-C6_sixteenth': 891,\n",
       " 'note-C6_sixteenth.': 892,\n",
       " 'note-C#6_sixty_fourth': 893,\n",
       " 'note-C6_sixty_fourth': 894,\n",
       " 'note-C#6_thirty_second': 895,\n",
       " 'note-C6_thirty_second': 896,\n",
       " 'note-C6_thirty_second.': 897,\n",
       " 'note-C6_whole': 898,\n",
       " 'note-C#6_whole_fermata': 899,\n",
       " 'note-C6_whole_fermata': 900,\n",
       " 'note-Cb3_eighth': 901,\n",
       " 'note-Cb3_quarter': 902,\n",
       " 'note-Cb3_thirty_second': 903,\n",
       " 'note-Cb4_eighth': 904,\n",
       " 'note-Cb4_eighth.': 905,\n",
       " 'note-Cb4_quarter': 906,\n",
       " 'note-Cb4_quarter.': 907,\n",
       " 'note-Cb4_sixteenth': 908,\n",
       " 'note-Cb4_whole': 909,\n",
       " 'note-Cb5_eighth': 910,\n",
       " 'note-Cb5_eighth.': 911,\n",
       " 'note-Cb5_half': 912,\n",
       " 'note-Cb5_half.': 913,\n",
       " 'note-Cb5_quarter': 914,\n",
       " 'note-Cb5_quarter.': 915,\n",
       " 'note-Cb5_sixteenth': 916,\n",
       " 'note-Cb5_thirty_second': 917,\n",
       " 'note-Cb5_whole': 918,\n",
       " 'note-Cb6_eighth': 919,\n",
       " 'note-Cb6_half': 920,\n",
       " 'note-Cb6_quarter': 921,\n",
       " 'note-Cb6_sixteenth': 922,\n",
       " 'note-Cb6_thirty_second': 923,\n",
       " 'note-D2_double_whole': 924,\n",
       " 'note-D2_eighth': 925,\n",
       " 'note-D2_eighth.': 926,\n",
       " 'note-D2_half': 927,\n",
       " 'note-D2_half.': 928,\n",
       " 'note-D2_half_fermata': 929,\n",
       " 'note-D#2_quarter': 930,\n",
       " 'note-D2_quarter': 931,\n",
       " 'note-D2_quarter.': 932,\n",
       " 'note-D2_quarter._fermata': 933,\n",
       " 'note-D#2_sixteenth': 934,\n",
       " 'note-D2_sixteenth': 935,\n",
       " 'note-D2_thirty_second': 936,\n",
       " 'note-D2_whole': 937,\n",
       " 'note-D3_double_whole': 938,\n",
       " 'note-D3_double_whole.': 939,\n",
       " 'note-D3_double_whole_fermata': 940,\n",
       " 'note-D#3_eighth': 941,\n",
       " 'note-D#3_eighth.': 942,\n",
       " 'note-D3_eighth': 943,\n",
       " 'note-D3_eighth.': 944,\n",
       " 'note-D3_eighth_fermata': 945,\n",
       " 'note-D#3_half': 946,\n",
       " 'note-D3_half': 947,\n",
       " 'note-D3_half.': 948,\n",
       " 'note-D#3_half_fermata': 949,\n",
       " 'note-D3_half_fermata': 950,\n",
       " 'note-D3_quadruple_whole': 951,\n",
       " 'note-D3_quadruple_whole_fermata': 952,\n",
       " 'note-D#3_quarter': 953,\n",
       " 'note-D#3_quarter.': 954,\n",
       " 'note-D3_quarter': 955,\n",
       " 'note-D3_quarter.': 956,\n",
       " 'note-D3_quarter..': 957,\n",
       " 'note-D3_quarter_fermata': 958,\n",
       " 'note-D3_quarter._fermata': 959,\n",
       " 'note-D#3_sixteenth': 960,\n",
       " 'note-D#3_sixteenth.': 961,\n",
       " 'note-D3_sixteenth': 962,\n",
       " 'note-D3_sixteenth.': 963,\n",
       " 'note-D3_sixty_fourth': 964,\n",
       " 'note-D#3_thirty_second': 965,\n",
       " 'note-D3_thirty_second': 966,\n",
       " 'note-D#3_whole': 967,\n",
       " 'note-D3_whole': 968,\n",
       " 'note-D3_whole.': 969,\n",
       " 'note-D3_whole_fermata': 970,\n",
       " 'note-D4_double_whole': 971,\n",
       " 'note-D4_double_whole.': 972,\n",
       " 'note-D4_double_whole_fermata': 973,\n",
       " 'note-D#4_eighth': 974,\n",
       " 'note-D#4_eighth.': 975,\n",
       " 'note-D4_eighth': 976,\n",
       " 'note-D4_eighth.': 977,\n",
       " 'note-D4_eighth..': 978,\n",
       " 'note-D4_eighth_fermata': 979,\n",
       " 'note-D4_eighth._fermata': 980,\n",
       " 'note-D#4_half': 981,\n",
       " 'note-D#4_half.': 982,\n",
       " 'note-D4_half': 983,\n",
       " 'note-D4_half.': 984,\n",
       " 'note-D4_half_fermata': 985,\n",
       " 'note-D4_half._fermata': 986,\n",
       " 'note-D4_hundred_twenty_eighth': 987,\n",
       " 'note-D4_quadruple_whole': 988,\n",
       " 'note-D4_quadruple_whole_fermata': 989,\n",
       " 'note-D#4_quarter': 990,\n",
       " 'note-D#4_quarter.': 991,\n",
       " 'note-D4_quarter': 992,\n",
       " 'note-D4_quarter.': 993,\n",
       " 'note-D4_quarter..': 994,\n",
       " 'note-D4_quarter_fermata': 995,\n",
       " 'note-D4_quarter._fermata': 996,\n",
       " 'note-D4_quarter.._fermata': 997,\n",
       " 'note-D#4_sixteenth': 998,\n",
       " 'note-D#4_sixteenth.': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obj.word2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'timeSignature-C/'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obj.int2word[1780]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1781",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\steli\\DeepLearning\\Project\\dl_omr\\notebooks\\ctc_model_fit_New_perspective.ipynb Cell 28'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000030?line=0'>1</a>\u001b[0m decoded_pred \u001b[39m=\u001b[39m data_obj\u001b[39m.\u001b[39;49mdecode_seqs(pred_indcies)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000030?line=1'>2</a>\u001b[0m decoded_pred\n",
      "\u001b[1;32mc:\\Users\\steli\\DeepLearning\\Project\\dl_omr\\notebooks\\ctc_model_fit_New_perspective.ipynb Cell 8'\u001b[0m in \u001b[0;36mPriMuS_Data.decode_seqs\u001b[1;34m(self, seqs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000007?line=49'>50</a>\u001b[0m new_seq\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000007?line=50'>51</a>\u001b[0m \u001b[39mfor\u001b[39;00m sym \u001b[39min\u001b[39;00m seq:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000007?line=51'>52</a>\u001b[0m     new_seq\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mint2word[sym] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000007?line=52'>53</a>\u001b[0m new_seq \u001b[39m=\u001b[39m new_seq[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steli/DeepLearning/Project/dl_omr/notebooks/ctc_model_fit_New_perspective.ipynb#ch0000007?line=53'>54</a>\u001b[0m decoded\u001b[39m.\u001b[39mappend(new_seq)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1781"
     ]
    }
   ],
   "source": [
    "decoded_pred = data_obj.decode_seqs(pred_indcies)\n",
    "decoded_pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9bbe03f6c4bbdf56f443191d16980388af1b731aba7be9951b0256cee325895"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
